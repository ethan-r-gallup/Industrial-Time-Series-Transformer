{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import logical_not\n",
    "from builderfuncs import EarlyStopAndSave\n",
    "from builderfuncs import build_gru, build_bigru, build_bilstm, build_lstm, save_whole_model, restore_model\n",
    "from parameterdicts import GRUParameters\n",
    "from ktfuncs import *\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/scaled_U2_data.csv', index_col=0)\n",
    "df.drop(\"UNNAMED: 0\", axis=1, inplace=True)\n",
    "\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttv_split(ds: tf.data.Dataset, ds_size: int, \n",
    "              train_split: float = 0.8, \n",
    "              val_split: float = 0.1, \n",
    "              test_split: float = 0.1) -> Tuple[tf.data.Dataset, \n",
    "                                                tf.data.Dataset, \n",
    "                                                tf.data.Dataset]:\n",
    "\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "   \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def split_window(features: tf.Tensor) -> Tuple[Dict[tf.Tensor, tf.Tensor],\n",
    "                                               tf.Tensor]:\n",
    "    inputs = features[:12, 1:]\n",
    "    state_labels = features[12, 75:]\n",
    "    targ_labels = tf.expand_dims(features[11, 0], axis=0)\n",
    "    labels = tf.concat([targ_labels, state_labels], axis=0)\n",
    "    inputs.set_shape([12, 247])\n",
    "    labels.set_shape([174])\n",
    "    \n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "                        \n",
    "def make_dataset(data: pd.DataFrame, length: int, \n",
    "                 batch_size: int = 64, multistep: bool = True) -> Tuple[tf.data.Dataset, \n",
    "                                                                        tf.data.Dataset, \n",
    "                                                                        tf.data.Dataset]:\n",
    "    data = np.array(data.iloc[:, :], dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(data=data,\n",
    "                                                        targets=None,\n",
    "                                                        sequence_length=length,\n",
    "                                                        sequence_stride=1,\n",
    "                                                        shuffle=True,\n",
    "                                                        seed=1,\n",
    "                                                        batch_size=None)\n",
    "\n",
    "    ds = ds.filter(lambda x: tf.reduce_all(logical_not(tf.math.is_nan(x))))\n",
    "    ds = ds.map(split_window).batch(batch_size)\n",
    "    ds = ds.apply(tf.data.experimental.assert_cardinality(170680//batch_size + 1))\n",
    "    train_ds, val_ds, test_ds = ttv_split(ds, 170680//batch_size, train_split=0.8, val_split=0.1, test_split=0.1)\n",
    "    train_ds = train_ds\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_logdir = os.path.join(\"logs\", 'gru-logs')\n",
    "gru_tensorboard_callback = tf.keras.callbacks.TensorBoard(gru_logdir, histogram_freq=1)\n",
    "gru_earlystopper = EarlyStopAndSave(filepath=\"model_folder/gru_folder\", patience=15, lim=0.005, minormax=\"max\")\n",
    "\n",
    "bigru_logdir = os.path.join(\"logs\", 'bigru-logs')\n",
    "bigru_tensorboard_callback = tf.keras.callbacks.TensorBoard(bigru_logdir, histogram_freq=1)\n",
    "bigru_earlystopper = EarlyStopAndSave(filepath=\"model_folder/bigru_folder\", patience=15, lim=0.005, minormax=\"max\")\n",
    "\n",
    "lstm_logdir = os.path.join(\"logs\", 'lstm-logs')\n",
    "lstm_tensorboard_callback = tf.keras.callbacks.TensorBoard(lstm_logdir, histogram_freq=1)\n",
    "lstm_earlystopper = EarlyStopAndSave(filepath=\"model_folder/lstm_folder\", patience=15, lim=0.005, minormax=\"max\")\n",
    "\n",
    "bilstm_logdir = os.path.join(\"logs\", 'bilstm-logs')\n",
    "bilstm_tensorboard_callback = tf.keras.callbacks.TensorBoard(bilstm_logdir, histogram_freq=1)\n",
    "bilstm_earlystopper = EarlyStopAndSave(filepath=\"model_folder/bilstm_folder\", patience=15, lim=0.005, minormax=\"max\")\n",
    "\n",
    "train_data, val_data, test_data = make_dataset(df, 23, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from directory\\gru_trial_1\\tuner0.json\n",
      "INFO:tensorflow:Reloading Tuner from directory\\bigru_trial_1\\tuner0.json\n",
      "INFO:tensorflow:Reloading Tuner from directory\\lstm_trial_1\\tuner0.json\n",
      "INFO:tensorflow:Reloading Tuner from directory\\bilstm_trial_1\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "gru_tuner = kt.BayesianOptimization(kt_gru,\n",
    "                                    objective=kt.Objective('val_loss', 'min'),\n",
    "                                    directory='directory',\n",
    "                                    project_name=\"gru_trial_1\",\n",
    "                                    seed=1)\n",
    "bigru_tuner = kt.BayesianOptimization(kt_bigru,\n",
    "                                    objective=kt.Objective('val_loss', 'min'),\n",
    "                                    directory='directory',\n",
    "                                    project_name=\"bigru_trial_1\",\n",
    "                                    seed=1)\n",
    "lstm_tuner = kt.BayesianOptimization(kt_lstm,\n",
    "                                    objective=kt.Objective('val_loss', 'min'),\n",
    "                                    directory='directory',\n",
    "                                    project_name=\"lstm_trial_1\",\n",
    "                                    seed=1)\n",
    "bilstm_tuner = kt.BayesianOptimization(kt_bilstm,\n",
    "                                    objective=kt.Objective('val_loss', 'min'),\n",
    "                                    directory='directory',\n",
    "                                    project_name=\"bilstm_trial_1\",\n",
    "                                    seed=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters: GRUParameters = gru_tuner.get_best_hyperparameters()[0].values\n",
    "parameters['look_back'] = parameters.pop('lookback')\n",
    "gru = build_gru(parameters=parameters, name=\"gru_model\", dynamic=False)\n",
    "\n",
    "parameters: GRUParameters = bigru_tuner.get_best_hyperparameters()[0].values\n",
    "parameters['look_back'] = parameters.pop('lookback')\n",
    "bigru = build_bigru(parameters=parameters, name=\"bigru_model\", dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2132/2132 - 45s - loss: 0.0066 - val_loss: 0.0021 - 45s/epoch - 21ms/step\n",
      "Epoch 2/200\n",
      "2132/2132 - 38s - loss: 0.0025 - val_loss: 0.0017 - 38s/epoch - 18ms/step\n",
      "Epoch 3/200\n",
      "2132/2132 - 42s - loss: 0.0022 - val_loss: 0.0016 - 42s/epoch - 20ms/step\n",
      "Epoch 4/200\n",
      "2132/2132 - 45s - loss: 0.0021 - val_loss: 0.0015 - 45s/epoch - 21ms/step\n",
      "Epoch 5/200\n",
      "2132/2132 - 44s - loss: 0.0020 - val_loss: 0.0014 - 44s/epoch - 21ms/step\n",
      "Epoch 6/200\n",
      "2132/2132 - 43s - loss: 0.0019 - val_loss: 0.0014 - 43s/epoch - 20ms/step\n",
      "Epoch 7/200\n",
      "2132/2132 - 42s - loss: 0.0018 - val_loss: 0.0013 - 42s/epoch - 20ms/step\n",
      "Epoch 8/200\n",
      "wait: 1\n",
      "2132/2132 - 43s - loss: 0.0018 - val_loss: 0.0013 - 43s/epoch - 20ms/step\n",
      "Epoch 9/200\n",
      "2132/2132 - 42s - loss: 0.0017 - val_loss: 0.0013 - 42s/epoch - 20ms/step\n",
      "Epoch 10/200\n",
      "2132/2132 - 46s - loss: 0.0017 - val_loss: 0.0012 - 46s/epoch - 22ms/step\n",
      "Epoch 11/200\n",
      "wait: 1\n",
      "2132/2132 - 47s - loss: 0.0016 - val_loss: 0.0013 - 47s/epoch - 22ms/step\n",
      "Epoch 12/200\n",
      "wait: 2\n",
      "2132/2132 - 45s - loss: 0.0016 - val_loss: 0.0012 - 45s/epoch - 21ms/step\n",
      "Epoch 13/200\n",
      "wait: 3\n",
      "2132/2132 - 46s - loss: 0.0015 - val_loss: 0.0012 - 46s/epoch - 21ms/step\n",
      "Epoch 14/200\n",
      "2132/2132 - 46s - loss: 0.0015 - val_loss: 0.0012 - 46s/epoch - 22ms/step\n",
      "Epoch 15/200\n",
      "2132/2132 - 45s - loss: 0.0015 - val_loss: 0.0012 - 45s/epoch - 21ms/step\n",
      "Epoch 16/200\n",
      "2132/2132 - 45s - loss: 0.0014 - val_loss: 0.0011 - 45s/epoch - 21ms/step\n",
      "Epoch 17/200\n",
      "wait: 1\n",
      "2132/2132 - 46s - loss: 0.0014 - val_loss: 0.0012 - 46s/epoch - 22ms/step\n",
      "Epoch 18/200\n",
      "wait: 2\n",
      "2132/2132 - 45s - loss: 0.0014 - val_loss: 0.0012 - 45s/epoch - 21ms/step\n",
      "Epoch 19/200\n",
      "2132/2132 - 48s - loss: 0.0013 - val_loss: 0.0011 - 48s/epoch - 22ms/step\n",
      "Epoch 20/200\n",
      "wait: 1\n",
      "2132/2132 - 47s - loss: 0.0013 - val_loss: 0.0012 - 47s/epoch - 22ms/step\n",
      "Epoch 21/200\n",
      "wait: 2\n",
      "2132/2132 - 46s - loss: 0.0013 - val_loss: 0.0011 - 46s/epoch - 21ms/step\n",
      "Epoch 22/200\n",
      "2132/2132 - 45s - loss: 0.0013 - val_loss: 0.0011 - 45s/epoch - 21ms/step\n",
      "Epoch 23/200\n",
      "wait: 1\n",
      "2132/2132 - 47s - loss: 0.0013 - val_loss: 0.0011 - 47s/epoch - 22ms/step\n",
      "Epoch 24/200\n",
      "wait: 2\n",
      "2132/2132 - 45s - loss: 0.0012 - val_loss: 0.0011 - 45s/epoch - 21ms/step\n",
      "Epoch 25/200\n",
      "wait: 3\n",
      "2132/2132 - 45s - loss: 0.0012 - val_loss: 0.0012 - 45s/epoch - 21ms/step\n",
      "Epoch 26/200\n",
      "wait: 4\n",
      "2132/2132 - 44s - loss: 0.0012 - val_loss: 0.0011 - 44s/epoch - 21ms/step\n",
      "Epoch 27/200\n",
      "2132/2132 - 44s - loss: 0.0012 - val_loss: 0.0011 - 44s/epoch - 20ms/step\n",
      "Epoch 28/200\n",
      "wait: 1\n",
      "2132/2132 - 44s - loss: 0.0012 - val_loss: 0.0011 - 44s/epoch - 21ms/step\n",
      "Epoch 29/200\n",
      "wait: 2\n",
      "2132/2132 - 44s - loss: 0.0011 - val_loss: 0.0011 - 44s/epoch - 21ms/step\n",
      "Epoch 30/200\n",
      "wait: 3\n",
      "2132/2132 - 45s - loss: 0.0011 - val_loss: 0.0011 - 45s/epoch - 21ms/step\n",
      "Epoch 31/200\n",
      "wait: 4\n",
      "2132/2132 - 45s - loss: 0.0011 - val_loss: 0.0011 - 45s/epoch - 21ms/step\n",
      "Epoch 32/200\n",
      "2132/2132 - 44s - loss: 0.0011 - val_loss: 0.0011 - 44s/epoch - 21ms/step\n",
      "Epoch 33/200\n",
      "wait: 1\n",
      "2132/2132 - 44s - loss: 0.0011 - val_loss: 0.0011 - 44s/epoch - 21ms/step\n",
      "Epoch 34/200\n",
      "wait: 2\n",
      "2132/2132 - 44s - loss: 0.0011 - val_loss: 0.0011 - 44s/epoch - 21ms/step\n",
      "Epoch 35/200\n",
      "wait: 3\n",
      "2132/2132 - 44s - loss: 0.0011 - val_loss: 0.0012 - 44s/epoch - 21ms/step\n",
      "Epoch 36/200\n",
      "wait: 4\n",
      "2132/2132 - 44s - loss: 0.0011 - val_loss: 0.0011 - 44s/epoch - 21ms/step\n",
      "Epoch 37/200\n",
      "wait: 5\n",
      "2132/2132 - 47s - loss: 0.0010 - val_loss: 0.0011 - 47s/epoch - 22ms/step\n",
      "Epoch 38/200\n",
      "wait: 6\n",
      "2132/2132 - 46s - loss: 0.0010 - val_loss: 0.0012 - 46s/epoch - 22ms/step\n",
      "Epoch 39/200\n",
      "wait: 7\n",
      "2132/2132 - 48s - loss: 0.0010 - val_loss: 0.0011 - 48s/epoch - 22ms/step\n",
      "Epoch 40/200\n",
      "wait: 8\n",
      "2132/2132 - 45s - loss: 0.0010 - val_loss: 0.0011 - 45s/epoch - 21ms/step\n",
      "Epoch 41/200\n",
      "wait: 9\n",
      "2132/2132 - 49s - loss: 0.0010 - val_loss: 0.0011 - 49s/epoch - 23ms/step\n",
      "Epoch 42/200\n",
      "wait: 10\n",
      "2132/2132 - 45s - loss: 0.0010 - val_loss: 0.0012 - 45s/epoch - 21ms/step\n",
      "Epoch 43/200\n",
      "wait: 11\n",
      "2132/2132 - 48s - loss: 9.9226e-04 - val_loss: 0.0012 - 48s/epoch - 22ms/step\n",
      "Epoch 44/200\n",
      "wait: 12\n",
      "2132/2132 - 47s - loss: 9.8402e-04 - val_loss: 0.0012 - 47s/epoch - 22ms/step\n",
      "Epoch 45/200\n",
      "wait: 13\n",
      "2132/2132 - 48s - loss: 9.7820e-04 - val_loss: 0.0011 - 48s/epoch - 23ms/step\n",
      "Epoch 46/200\n",
      "wait: 14\n",
      "2132/2132 - 46s - loss: 9.7295e-04 - val_loss: 0.0012 - 46s/epoch - 22ms/step\n",
      "Epoch 47/200\n",
      "wait: 15\n",
      "2132/2132 - 45s - loss: 9.6635e-04 - val_loss: 0.0011 - 45s/epoch - 21ms/step\n",
      "Epoch 1/200\n",
      "2132/2132 - 89s - loss: 0.0048 - val_loss: 0.0017 - 89s/epoch - 42ms/step\n",
      "Epoch 2/200\n",
      "2132/2132 - 83s - loss: 0.0021 - val_loss: 0.0015 - 83s/epoch - 39ms/step\n",
      "Epoch 3/200\n",
      "2132/2132 - 95s - loss: 0.0018 - val_loss: 0.0013 - 95s/epoch - 44ms/step\n",
      "Epoch 4/200\n",
      "2132/2132 - 88s - loss: 0.0017 - val_loss: 0.0012 - 88s/epoch - 41ms/step\n",
      "Epoch 5/200\n",
      "2132/2132 - 90s - loss: 0.0016 - val_loss: 0.0012 - 90s/epoch - 42ms/step\n",
      "Epoch 6/200\n",
      "2132/2132 - 85s - loss: 0.0015 - val_loss: 0.0011 - 85s/epoch - 40ms/step\n",
      "Epoch 7/200\n",
      "2132/2132 - 98s - loss: 0.0015 - val_loss: 0.0011 - 98s/epoch - 46ms/step\n",
      "Epoch 8/200\n",
      "2132/2132 - 84s - loss: 0.0014 - val_loss: 0.0011 - 84s/epoch - 39ms/step\n",
      "Epoch 9/200\n",
      "2132/2132 - 84s - loss: 0.0014 - val_loss: 0.0011 - 84s/epoch - 39ms/step\n",
      "Epoch 10/200\n",
      "2132/2132 - 102s - loss: 0.0014 - val_loss: 0.0010 - 102s/epoch - 48ms/step\n",
      "Epoch 11/200\n",
      "2132/2132 - 83s - loss: 0.0013 - val_loss: 0.0010 - 83s/epoch - 39ms/step\n",
      "Epoch 12/200\n",
      "2132/2132 - 84s - loss: 0.0013 - val_loss: 9.9957e-04 - 84s/epoch - 39ms/step\n",
      "Epoch 13/200\n",
      "wait: 1\n",
      "2132/2132 - 97s - loss: 0.0013 - val_loss: 0.0010 - 97s/epoch - 46ms/step\n",
      "Epoch 14/200\n",
      "2132/2132 - 84s - loss: 0.0012 - val_loss: 9.8896e-04 - 84s/epoch - 40ms/step\n",
      "Epoch 15/200\n",
      "2132/2132 - 101s - loss: 0.0012 - val_loss: 9.5706e-04 - 101s/epoch - 47ms/step\n",
      "Epoch 16/200\n",
      "wait: 1\n",
      "2132/2132 - 83s - loss: 0.0012 - val_loss: 9.7294e-04 - 83s/epoch - 39ms/step\n",
      "Epoch 17/200\n",
      "wait: 2\n",
      "2132/2132 - 101s - loss: 0.0012 - val_loss: 9.6373e-04 - 101s/epoch - 48ms/step\n",
      "Epoch 18/200\n",
      "2132/2132 - 87s - loss: 0.0012 - val_loss: 9.5242e-04 - 87s/epoch - 41ms/step\n",
      "Epoch 19/200\n",
      "2132/2132 - 103s - loss: 0.0012 - val_loss: 9.4869e-04 - 103s/epoch - 48ms/step\n",
      "Epoch 20/200\n",
      "2132/2132 - 83s - loss: 0.0011 - val_loss: 9.2540e-04 - 83s/epoch - 39ms/step\n",
      "Epoch 21/200\n",
      "2132/2132 - 122s - loss: 0.0011 - val_loss: 9.2028e-04 - 122s/epoch - 57ms/step\n",
      "Epoch 22/200\n",
      "wait: 1\n",
      "2132/2132 - 86s - loss: 0.0011 - val_loss: 9.5225e-04 - 86s/epoch - 40ms/step\n",
      "Epoch 23/200\n",
      "2132/2132 - 101s - loss: 0.0011 - val_loss: 9.1904e-04 - 101s/epoch - 47ms/step\n",
      "Epoch 24/200\n",
      "2132/2132 - 89s - loss: 0.0011 - val_loss: 8.9612e-04 - 89s/epoch - 42ms/step\n",
      "Epoch 25/200\n",
      "wait: 1\n",
      "2132/2132 - 91s - loss: 0.0011 - val_loss: 9.0388e-04 - 91s/epoch - 43ms/step\n",
      "Epoch 26/200\n",
      "wait: 2\n",
      "2132/2132 - 87s - loss: 0.0010 - val_loss: 9.0258e-04 - 87s/epoch - 41ms/step\n",
      "Epoch 27/200\n",
      "2132/2132 - 109s - loss: 0.0010 - val_loss: 8.9239e-04 - 109s/epoch - 51ms/step\n",
      "Epoch 28/200\n",
      "2132/2132 - 105s - loss: 0.0010 - val_loss: 8.9182e-04 - 105s/epoch - 49ms/step\n",
      "Epoch 29/200\n",
      "wait: 1\n",
      "2132/2132 - 89s - loss: 9.9987e-04 - val_loss: 9.0513e-04 - 89s/epoch - 42ms/step\n",
      "Epoch 30/200\n",
      "wait: 2\n",
      "2132/2132 - 115s - loss: 9.8717e-04 - val_loss: 9.2342e-04 - 115s/epoch - 54ms/step\n",
      "Epoch 31/200\n",
      "2132/2132 - 95s - loss: 9.7721e-04 - val_loss: 8.8963e-04 - 95s/epoch - 45ms/step\n",
      "Epoch 32/200\n",
      "2132/2132 - 109s - loss: 9.6654e-04 - val_loss: 8.6406e-04 - 109s/epoch - 51ms/step\n",
      "Epoch 33/200\n",
      "wait: 1\n",
      "2132/2132 - 100s - loss: 9.5705e-04 - val_loss: 8.8451e-04 - 100s/epoch - 47ms/step\n",
      "Epoch 34/200\n",
      "wait: 2\n",
      "2132/2132 - 105s - loss: 9.4848e-04 - val_loss: 8.7563e-04 - 105s/epoch - 49ms/step\n",
      "Epoch 35/200\n",
      "wait: 3\n",
      "2132/2132 - 89s - loss: 9.3903e-04 - val_loss: 9.3044e-04 - 89s/epoch - 42ms/step\n",
      "Epoch 36/200\n",
      "wait: 4\n",
      "2132/2132 - 91s - loss: 9.3298e-04 - val_loss: 9.0716e-04 - 91s/epoch - 43ms/step\n",
      "Epoch 37/200\n",
      "wait: 5\n",
      "2132/2132 - 105s - loss: 9.2362e-04 - val_loss: 9.3666e-04 - 105s/epoch - 49ms/step\n",
      "Epoch 38/200\n",
      "wait: 6\n",
      "2132/2132 - 109s - loss: 9.1793e-04 - val_loss: 8.9928e-04 - 109s/epoch - 51ms/step\n",
      "Epoch 39/200\n",
      "wait: 7\n",
      "2132/2132 - 86s - loss: 9.1131e-04 - val_loss: 9.3680e-04 - 86s/epoch - 40ms/step\n",
      "Epoch 40/200\n",
      "wait: 8\n",
      "2132/2132 - 111s - loss: 9.0510e-04 - val_loss: 9.1396e-04 - 111s/epoch - 52ms/step\n",
      "Epoch 41/200\n",
      "wait: 9\n",
      "2132/2132 - 102s - loss: 8.9876e-04 - val_loss: 9.3060e-04 - 102s/epoch - 48ms/step\n",
      "Epoch 42/200\n",
      "wait: 10\n",
      "2132/2132 - 97s - loss: 8.9151e-04 - val_loss: 8.9901e-04 - 97s/epoch - 45ms/step\n",
      "Epoch 43/200\n",
      "wait: 11\n",
      "2132/2132 - 109s - loss: 8.8795e-04 - val_loss: 8.9986e-04 - 109s/epoch - 51ms/step\n",
      "Epoch 44/200\n",
      "wait: 12\n",
      "2132/2132 - 90s - loss: 8.8012e-04 - val_loss: 9.2762e-04 - 90s/epoch - 42ms/step\n",
      "Epoch 45/200\n",
      "wait: 13\n",
      "2132/2132 - 110s - loss: 8.7588e-04 - val_loss: 9.1960e-04 - 110s/epoch - 51ms/step\n",
      "Epoch 46/200\n",
      "wait: 14\n",
      "2132/2132 - 112s - loss: 8.6914e-04 - val_loss: 9.2264e-04 - 112s/epoch - 52ms/step\n",
      "Epoch 47/200\n",
      "wait: 15\n",
      "2132/2132 - 102s - loss: 8.6509e-04 - val_loss: 9.0932e-04 - 102s/epoch - 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a755a740d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.fit(train_data, epochs=200, verbose=2, validation_data=val_data, callbacks=[gru_earlystopper, gru_tensorboard_callback])\n",
    "bigru.fit(train_data, epochs=200, verbose=2, validation_data=val_data, callbacks=[bigru_earlystopper, bigru_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters: GRUParameters = lstm_tuner.get_best_hyperparameters()[0].values\n",
    "parameters['look_back'] = parameters.pop('lookback')\n",
    "lstm = build_lstm(parameters=parameters, name=\"lstm_model\", dynamic=False)\n",
    "\n",
    "parameters: GRUParameters = bilstm_tuner.get_best_hyperparameters()[0].values\n",
    "parameters['look_back'] = parameters.pop('lookback')\n",
    "bilstm = build_bilstm(parameters=parameters, name=\"bilstm_model\", dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2132/2132 - 63s - loss: 0.0055 - val_loss: 0.0019 - 63s/epoch - 30ms/step\n",
      "Epoch 2/200\n",
      "2132/2132 - 60s - loss: 0.0023 - val_loss: 0.0016 - 60s/epoch - 28ms/step\n",
      "Epoch 3/200\n",
      "2132/2132 - 62s - loss: 0.0020 - val_loss: 0.0015 - 62s/epoch - 29ms/step\n",
      "Epoch 4/200\n",
      "2132/2132 - 66s - loss: 0.0018 - val_loss: 0.0014 - 66s/epoch - 31ms/step\n",
      "Epoch 5/200\n",
      "2132/2132 - 64s - loss: 0.0017 - val_loss: 0.0013 - 64s/epoch - 30ms/step\n",
      "Epoch 6/200\n",
      "wait: 1\n",
      "2132/2132 - 66s - loss: 0.0017 - val_loss: 0.0013 - 66s/epoch - 31ms/step\n",
      "Epoch 7/200\n",
      "2132/2132 - 59s - loss: 0.0016 - val_loss: 0.0012 - 59s/epoch - 28ms/step\n",
      "Epoch 8/200\n",
      "wait: 1\n",
      "2132/2132 - 57s - loss: 0.0016 - val_loss: 0.0012 - 57s/epoch - 27ms/step\n",
      "Epoch 9/200\n",
      "2132/2132 - 56s - loss: 0.0015 - val_loss: 0.0012 - 56s/epoch - 26ms/step\n",
      "Epoch 10/200\n",
      "2132/2132 - 58s - loss: 0.0015 - val_loss: 0.0012 - 58s/epoch - 27ms/step\n",
      "Epoch 11/200\n",
      "wait: 1\n",
      "2132/2132 - 58s - loss: 0.0015 - val_loss: 0.0012 - 58s/epoch - 27ms/step\n",
      "Epoch 12/200\n",
      "2132/2132 - 58s - loss: 0.0014 - val_loss: 0.0011 - 58s/epoch - 27ms/step\n",
      "Epoch 13/200\n",
      "wait: 1\n",
      "2132/2132 - 58s - loss: 0.0014 - val_loss: 0.0011 - 58s/epoch - 27ms/step\n",
      "Epoch 14/200\n",
      "2132/2132 - 59s - loss: 0.0014 - val_loss: 0.0011 - 59s/epoch - 28ms/step\n",
      "Epoch 15/200\n",
      "2132/2132 - 56s - loss: 0.0014 - val_loss: 0.0011 - 56s/epoch - 26ms/step\n",
      "Epoch 16/200\n",
      "2132/2132 - 59s - loss: 0.0013 - val_loss: 0.0011 - 59s/epoch - 28ms/step\n",
      "Epoch 17/200\n",
      "2132/2132 - 59s - loss: 0.0013 - val_loss: 0.0011 - 59s/epoch - 28ms/step\n",
      "Epoch 18/200\n",
      "wait: 1\n",
      "2132/2132 - 58s - loss: 0.0013 - val_loss: 0.0011 - 58s/epoch - 27ms/step\n",
      "Epoch 19/200\n",
      "2132/2132 - 59s - loss: 0.0013 - val_loss: 0.0010 - 59s/epoch - 28ms/step\n",
      "Epoch 20/200\n",
      "wait: 1\n",
      "2132/2132 - 57s - loss: 0.0013 - val_loss: 0.0010 - 57s/epoch - 27ms/step\n",
      "Epoch 21/200\n",
      "2132/2132 - 62s - loss: 0.0012 - val_loss: 0.0010 - 62s/epoch - 29ms/step\n",
      "Epoch 22/200\n",
      "wait: 1\n",
      "2132/2132 - 59s - loss: 0.0012 - val_loss: 0.0010 - 59s/epoch - 28ms/step\n",
      "Epoch 23/200\n",
      "wait: 2\n",
      "2132/2132 - 59s - loss: 0.0012 - val_loss: 0.0010 - 59s/epoch - 27ms/step\n",
      "Epoch 24/200\n",
      "2132/2132 - 58s - loss: 0.0012 - val_loss: 0.0010 - 58s/epoch - 27ms/step\n",
      "Epoch 25/200\n",
      "2132/2132 - 56s - loss: 0.0012 - val_loss: 0.0010 - 56s/epoch - 26ms/step\n",
      "Epoch 26/200\n",
      "2132/2132 - 61s - loss: 0.0012 - val_loss: 0.0010 - 61s/epoch - 28ms/step\n",
      "Epoch 27/200\n",
      "2132/2132 - 58s - loss: 0.0012 - val_loss: 9.8436e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 28/200\n",
      "wait: 1\n",
      "2132/2132 - 57s - loss: 0.0011 - val_loss: 0.0011 - 57s/epoch - 27ms/step\n",
      "Epoch 29/200\n",
      "2132/2132 - 58s - loss: 0.0011 - val_loss: 9.7419e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 30/200\n",
      "wait: 1\n",
      "2132/2132 - 59s - loss: 0.0011 - val_loss: 0.0010 - 59s/epoch - 28ms/step\n",
      "Epoch 31/200\n",
      "wait: 2\n",
      "2132/2132 - 60s - loss: 0.0011 - val_loss: 0.0010 - 60s/epoch - 28ms/step\n",
      "Epoch 32/200\n",
      "wait: 3\n",
      "2132/2132 - 58s - loss: 0.0011 - val_loss: 9.9540e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 33/200\n",
      "2132/2132 - 57s - loss: 0.0011 - val_loss: 9.6059e-04 - 57s/epoch - 27ms/step\n",
      "Epoch 34/200\n",
      "2132/2132 - 59s - loss: 0.0011 - val_loss: 9.5440e-04 - 59s/epoch - 27ms/step\n",
      "Epoch 35/200\n",
      "wait: 1\n",
      "2132/2132 - 59s - loss: 0.0011 - val_loss: 9.7928e-04 - 59s/epoch - 28ms/step\n",
      "Epoch 36/200\n",
      "wait: 2\n",
      "2132/2132 - 58s - loss: 0.0011 - val_loss: 9.8309e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 37/200\n",
      "wait: 3\n",
      "2132/2132 - 58s - loss: 0.0011 - val_loss: 0.0010 - 58s/epoch - 27ms/step\n",
      "Epoch 38/200\n",
      "2132/2132 - 62s - loss: 0.0010 - val_loss: 9.5189e-04 - 62s/epoch - 29ms/step\n",
      "Epoch 39/200\n",
      "2132/2132 - 59s - loss: 0.0010 - val_loss: 9.4222e-04 - 59s/epoch - 27ms/step\n",
      "Epoch 40/200\n",
      "wait: 1\n",
      "2132/2132 - 58s - loss: 0.0010 - val_loss: 9.5546e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 41/200\n",
      "wait: 2\n",
      "2132/2132 - 61s - loss: 0.0010 - val_loss: 9.7506e-04 - 61s/epoch - 28ms/step\n",
      "Epoch 42/200\n",
      "wait: 3\n",
      "2132/2132 - 61s - loss: 0.0010 - val_loss: 9.6101e-04 - 61s/epoch - 29ms/step\n",
      "Epoch 43/200\n",
      "2132/2132 - 61s - loss: 9.9787e-04 - val_loss: 9.2377e-04 - 61s/epoch - 28ms/step\n",
      "Epoch 44/200\n",
      "wait: 1\n",
      "2132/2132 - 59s - loss: 9.8566e-04 - val_loss: 9.3599e-04 - 59s/epoch - 28ms/step\n",
      "Epoch 45/200\n",
      "2132/2132 - 57s - loss: 9.7817e-04 - val_loss: 9.1712e-04 - 57s/epoch - 27ms/step\n",
      "Epoch 46/200\n",
      "wait: 1\n",
      "2132/2132 - 57s - loss: 9.7007e-04 - val_loss: 9.3461e-04 - 57s/epoch - 27ms/step\n",
      "Epoch 47/200\n",
      "wait: 2\n",
      "2132/2132 - 61s - loss: 9.6046e-04 - val_loss: 9.4069e-04 - 61s/epoch - 29ms/step\n",
      "Epoch 48/200\n",
      "2132/2132 - 59s - loss: 9.5024e-04 - val_loss: 9.1384e-04 - 59s/epoch - 27ms/step\n",
      "Epoch 49/200\n",
      "wait: 1\n",
      "2132/2132 - 59s - loss: 9.4140e-04 - val_loss: 9.2657e-04 - 59s/epoch - 28ms/step\n",
      "Epoch 50/200\n",
      "wait: 2\n",
      "2132/2132 - 60s - loss: 9.3344e-04 - val_loss: 9.1457e-04 - 60s/epoch - 28ms/step\n",
      "Epoch 51/200\n",
      "2132/2132 - 62s - loss: 9.2546e-04 - val_loss: 8.9162e-04 - 62s/epoch - 29ms/step\n",
      "Epoch 52/200\n",
      "wait: 1\n",
      "2132/2132 - 58s - loss: 9.1785e-04 - val_loss: 9.2568e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 53/200\n",
      "wait: 2\n",
      "2132/2132 - 55s - loss: 9.1120e-04 - val_loss: 9.1052e-04 - 55s/epoch - 26ms/step\n",
      "Epoch 54/200\n",
      "2132/2132 - 60s - loss: 9.0602e-04 - val_loss: 8.8606e-04 - 60s/epoch - 28ms/step\n",
      "Epoch 55/200\n",
      "wait: 1\n",
      "2132/2132 - 64s - loss: 8.9738e-04 - val_loss: 9.4846e-04 - 64s/epoch - 30ms/step\n",
      "Epoch 56/200\n",
      "wait: 2\n",
      "2132/2132 - 75s - loss: 8.9281e-04 - val_loss: 9.1828e-04 - 75s/epoch - 35ms/step\n",
      "Epoch 57/200\n",
      "2132/2132 - 61s - loss: 8.8563e-04 - val_loss: 8.8153e-04 - 61s/epoch - 29ms/step\n",
      "Epoch 58/200\n",
      "wait: 1\n",
      "2132/2132 - 64s - loss: 8.7962e-04 - val_loss: 9.3464e-04 - 64s/epoch - 30ms/step\n",
      "Epoch 59/200\n",
      "2132/2132 - 62s - loss: 8.7377e-04 - val_loss: 8.6658e-04 - 62s/epoch - 29ms/step\n",
      "Epoch 60/200\n",
      "wait: 1\n",
      "2132/2132 - 64s - loss: 8.6637e-04 - val_loss: 9.3430e-04 - 64s/epoch - 30ms/step\n",
      "Epoch 61/200\n",
      "wait: 2\n",
      "2132/2132 - 68s - loss: 8.6113e-04 - val_loss: 9.3076e-04 - 68s/epoch - 32ms/step\n",
      "Epoch 62/200\n",
      "wait: 3\n",
      "2132/2132 - 65s - loss: 8.5495e-04 - val_loss: 9.2928e-04 - 65s/epoch - 30ms/step\n",
      "Epoch 63/200\n",
      "wait: 4\n",
      "2132/2132 - 81s - loss: 8.4931e-04 - val_loss: 9.1523e-04 - 81s/epoch - 38ms/step\n",
      "Epoch 64/200\n",
      "wait: 5\n",
      "2132/2132 - 62s - loss: 8.4602e-04 - val_loss: 8.8069e-04 - 62s/epoch - 29ms/step\n",
      "Epoch 65/200\n",
      "wait: 6\n",
      "2132/2132 - 59s - loss: 8.4031e-04 - val_loss: 9.4188e-04 - 59s/epoch - 28ms/step\n",
      "Epoch 66/200\n",
      "wait: 7\n",
      "2132/2132 - 60s - loss: 8.3586e-04 - val_loss: 9.1153e-04 - 60s/epoch - 28ms/step\n",
      "Epoch 67/200\n",
      "wait: 8\n",
      "2132/2132 - 59s - loss: 8.3358e-04 - val_loss: 9.2190e-04 - 59s/epoch - 28ms/step\n",
      "Epoch 68/200\n",
      "wait: 9\n",
      "2132/2132 - 60s - loss: 8.2730e-04 - val_loss: 8.9226e-04 - 60s/epoch - 28ms/step\n",
      "Epoch 69/200\n",
      "wait: 10\n",
      "2132/2132 - 60s - loss: 8.2136e-04 - val_loss: 9.0253e-04 - 60s/epoch - 28ms/step\n",
      "Epoch 70/200\n",
      "wait: 11\n",
      "2132/2132 - 59s - loss: 8.1699e-04 - val_loss: 9.0367e-04 - 59s/epoch - 28ms/step\n",
      "Epoch 71/200\n",
      "wait: 12\n",
      "2132/2132 - 59s - loss: 8.1484e-04 - val_loss: 9.2844e-04 - 59s/epoch - 28ms/step\n",
      "Epoch 72/200\n",
      "wait: 13\n",
      "2132/2132 - 58s - loss: 8.0897e-04 - val_loss: 9.0237e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 73/200\n",
      "wait: 14\n",
      "2132/2132 - 58s - loss: 8.0581e-04 - val_loss: 9.0780e-04 - 58s/epoch - 27ms/step\n",
      "Epoch 74/200\n",
      "wait: 15\n",
      "2132/2132 - 55s - loss: 8.0062e-04 - val_loss: 9.6260e-04 - 55s/epoch - 26ms/step\n",
      "Epoch 1/200\n",
      "2132/2132 - 128s - loss: 0.0043 - val_loss: 0.0016 - 128s/epoch - 60ms/step\n",
      "Epoch 2/200\n",
      "2132/2132 - 133s - loss: 0.0019 - val_loss: 0.0014 - 133s/epoch - 62ms/step\n",
      "Epoch 3/200\n",
      "2132/2132 - 120s - loss: 0.0016 - val_loss: 0.0013 - 120s/epoch - 56ms/step\n",
      "Epoch 4/200\n",
      "2132/2132 - 128s - loss: 0.0015 - val_loss: 0.0011 - 128s/epoch - 60ms/step\n",
      "Epoch 5/200\n",
      "2132/2132 - 131s - loss: 0.0014 - val_loss: 0.0011 - 131s/epoch - 61ms/step\n",
      "Epoch 6/200\n",
      "2132/2132 - 121s - loss: 0.0014 - val_loss: 0.0011 - 121s/epoch - 57ms/step\n",
      "Epoch 7/200\n",
      "2132/2132 - 143s - loss: 0.0013 - val_loss: 0.0010 - 143s/epoch - 67ms/step\n",
      "Epoch 8/200\n",
      "2132/2132 - 118s - loss: 0.0013 - val_loss: 9.9676e-04 - 118s/epoch - 55ms/step\n",
      "Epoch 9/200\n",
      "2132/2132 - 137s - loss: 0.0013 - val_loss: 9.9532e-04 - 137s/epoch - 64ms/step\n",
      "Epoch 10/200\n",
      "2132/2132 - 135s - loss: 0.0012 - val_loss: 9.7605e-04 - 135s/epoch - 63ms/step\n",
      "Epoch 11/200\n",
      "2132/2132 - 120s - loss: 0.0012 - val_loss: 9.7503e-04 - 120s/epoch - 56ms/step\n",
      "Epoch 12/200\n",
      "2132/2132 - 137s - loss: 0.0012 - val_loss: 9.4456e-04 - 137s/epoch - 64ms/step\n",
      "Epoch 13/200\n",
      "2132/2132 - 118s - loss: 0.0012 - val_loss: 9.3813e-04 - 118s/epoch - 55ms/step\n",
      "Epoch 14/200\n",
      "2132/2132 - 138s - loss: 0.0011 - val_loss: 9.1231e-04 - 138s/epoch - 65ms/step\n",
      "Epoch 15/200\n",
      "2132/2132 - 135s - loss: 0.0011 - val_loss: 9.0369e-04 - 135s/epoch - 63ms/step\n",
      "Epoch 16/200\n",
      "wait: 1\n",
      "2132/2132 - 121s - loss: 0.0011 - val_loss: 9.1847e-04 - 121s/epoch - 57ms/step\n",
      "Epoch 17/200\n",
      "2132/2132 - 140s - loss: 0.0011 - val_loss: 8.8700e-04 - 140s/epoch - 66ms/step\n",
      "Epoch 18/200\n",
      "wait: 1\n",
      "2132/2132 - 156s - loss: 0.0011 - val_loss: 9.0823e-04 - 156s/epoch - 73ms/step\n",
      "Epoch 19/200\n",
      "wait: 2\n",
      "2132/2132 - 126s - loss: 0.0011 - val_loss: 9.0184e-04 - 126s/epoch - 59ms/step\n",
      "Epoch 20/200\n",
      "2132/2132 - 128s - loss: 0.0010 - val_loss: 8.7191e-04 - 128s/epoch - 60ms/step\n",
      "Epoch 21/200\n",
      "wait: 1\n",
      "2132/2132 - 143s - loss: 0.0010 - val_loss: 8.7509e-04 - 143s/epoch - 67ms/step\n",
      "Epoch 22/200\n",
      "2132/2132 - 140s - loss: 0.0010 - val_loss: 8.6096e-04 - 140s/epoch - 65ms/step\n",
      "Epoch 23/200\n",
      "wait: 1\n",
      "2132/2132 - 133s - loss: 0.0010 - val_loss: 8.9355e-04 - 133s/epoch - 63ms/step\n",
      "Epoch 24/200\n",
      "wait: 2\n",
      "2132/2132 - 137s - loss: 9.9497e-04 - val_loss: 8.7986e-04 - 137s/epoch - 64ms/step\n",
      "Epoch 25/200\n",
      "2132/2132 - 132s - loss: 9.8224e-04 - val_loss: 8.6087e-04 - 132s/epoch - 62ms/step\n",
      "Epoch 26/200\n",
      "2132/2132 - 115s - loss: 9.7518e-04 - val_loss: 8.5656e-04 - 115s/epoch - 54ms/step\n",
      "Epoch 27/200\n",
      "2132/2132 - 144s - loss: 9.6245e-04 - val_loss: 8.5484e-04 - 144s/epoch - 67ms/step\n",
      "Epoch 28/200\n",
      "2132/2132 - 120s - loss: 9.5483e-04 - val_loss: 8.4840e-04 - 120s/epoch - 56ms/step\n",
      "Epoch 29/200\n",
      "wait: 1\n",
      "2132/2132 - 133s - loss: 9.4523e-04 - val_loss: 8.7308e-04 - 133s/epoch - 62ms/step\n",
      "Epoch 30/200\n",
      "2132/2132 - 133s - loss: 9.3553e-04 - val_loss: 8.4641e-04 - 133s/epoch - 62ms/step\n",
      "Epoch 31/200\n",
      "2132/2132 - 130s - loss: 9.2593e-04 - val_loss: 8.2363e-04 - 130s/epoch - 61ms/step\n",
      "Epoch 32/200\n",
      "wait: 1\n",
      "2132/2132 - 117s - loss: 9.1822e-04 - val_loss: 8.6446e-04 - 117s/epoch - 55ms/step\n",
      "Epoch 33/200\n",
      "2132/2132 - 163s - loss: 9.0954e-04 - val_loss: 8.0575e-04 - 163s/epoch - 77ms/step\n",
      "Epoch 34/200\n",
      "wait: 1\n",
      "2132/2132 - 142s - loss: 8.9982e-04 - val_loss: 8.1836e-04 - 142s/epoch - 67ms/step\n",
      "Epoch 35/200\n",
      "2132/2132 - 119s - loss: 8.9072e-04 - val_loss: 7.9921e-04 - 119s/epoch - 56ms/step\n",
      "Epoch 36/200\n",
      "wait: 1\n",
      "2132/2132 - 152s - loss: 8.8377e-04 - val_loss: 8.1049e-04 - 152s/epoch - 71ms/step\n",
      "Epoch 37/200\n",
      "wait: 2\n",
      "2132/2132 - 131s - loss: 8.7273e-04 - val_loss: 8.5102e-04 - 131s/epoch - 61ms/step\n",
      "Epoch 38/200\n",
      "wait: 3\n",
      "2132/2132 - 153s - loss: 8.6539e-04 - val_loss: 8.1833e-04 - 153s/epoch - 72ms/step\n",
      "Epoch 39/200\n",
      "wait: 4\n",
      "2132/2132 - 142s - loss: 8.5278e-04 - val_loss: 8.2556e-04 - 142s/epoch - 67ms/step\n",
      "Epoch 40/200\n",
      "wait: 5\n",
      "2132/2132 - 141s - loss: 8.4382e-04 - val_loss: 8.2884e-04 - 141s/epoch - 66ms/step\n",
      "Epoch 41/200\n",
      "wait: 6\n",
      "2132/2132 - 157s - loss: 8.3157e-04 - val_loss: 8.0310e-04 - 157s/epoch - 73ms/step\n",
      "Epoch 42/200\n",
      "2132/2132 - 140s - loss: 8.2341e-04 - val_loss: 7.9279e-04 - 140s/epoch - 66ms/step\n",
      "Epoch 43/200\n",
      "2132/2132 - 143s - loss: 8.1707e-04 - val_loss: 7.8457e-04 - 143s/epoch - 67ms/step\n",
      "Epoch 44/200\n",
      "wait: 1\n",
      "2132/2132 - 176s - loss: 8.0734e-04 - val_loss: 8.5622e-04 - 176s/epoch - 83ms/step\n",
      "Epoch 45/200\n",
      "wait: 2\n",
      "2132/2132 - 132s - loss: 7.9918e-04 - val_loss: 7.9410e-04 - 132s/epoch - 62ms/step\n",
      "Epoch 46/200\n",
      "wait: 3\n",
      "2132/2132 - 125s - loss: 7.9143e-04 - val_loss: 8.3093e-04 - 125s/epoch - 58ms/step\n",
      "Epoch 47/200\n",
      "wait: 4\n",
      "2132/2132 - 133s - loss: 7.8394e-04 - val_loss: 8.0580e-04 - 133s/epoch - 62ms/step\n",
      "Epoch 48/200\n",
      "wait: 5\n",
      "2132/2132 - 136s - loss: 7.7690e-04 - val_loss: 8.0811e-04 - 136s/epoch - 64ms/step\n",
      "Epoch 49/200\n",
      "wait: 6\n",
      "2132/2132 - 122s - loss: 7.7281e-04 - val_loss: 7.9663e-04 - 122s/epoch - 57ms/step\n",
      "Epoch 50/200\n",
      "wait: 7\n",
      "2132/2132 - 137s - loss: 7.6517e-04 - val_loss: 8.2200e-04 - 137s/epoch - 64ms/step\n",
      "Epoch 51/200\n",
      "wait: 8\n",
      "2132/2132 - 140s - loss: 7.6015e-04 - val_loss: 7.9333e-04 - 140s/epoch - 66ms/step\n",
      "Epoch 52/200\n",
      "wait: 9\n",
      "2132/2132 - 112s - loss: 7.5469e-04 - val_loss: 8.0538e-04 - 112s/epoch - 52ms/step\n",
      "Epoch 53/200\n",
      "wait: 10\n",
      "2132/2132 - 131s - loss: 7.4840e-04 - val_loss: 7.9501e-04 - 131s/epoch - 62ms/step\n",
      "Epoch 54/200\n",
      "wait: 11\n",
      "2132/2132 - 129s - loss: 7.4288e-04 - val_loss: 8.1566e-04 - 129s/epoch - 60ms/step\n",
      "Epoch 55/200\n",
      "wait: 12\n",
      "2132/2132 - 147s - loss: 7.3927e-04 - val_loss: 7.9769e-04 - 147s/epoch - 69ms/step\n",
      "Epoch 56/200\n",
      "wait: 13\n",
      "2132/2132 - 129s - loss: 7.3344e-04 - val_loss: 8.2696e-04 - 129s/epoch - 60ms/step\n",
      "Epoch 57/200\n",
      "wait: 14\n",
      "2132/2132 - 120s - loss: 7.2731e-04 - val_loss: 8.2469e-04 - 120s/epoch - 56ms/step\n",
      "Epoch 58/200\n",
      "wait: 15\n",
      "2132/2132 - 139s - loss: 7.2441e-04 - val_loss: 7.9428e-04 - 139s/epoch - 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a75414baf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(train_data, epochs=200, verbose=2, validation_data=val_data, callbacks=[lstm_earlystopper, lstm_tensorboard_callback])\n",
    "bilstm.fit(train_data, epochs=200, verbose=2, validation_data=val_data, callbacks=[bilstm_earlystopper, bilstm_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ToApps.to_apps import to_slack\n",
    "to_slack(\"DONE\\n START NEXT PROGRAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_proj_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
