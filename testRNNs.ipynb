{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import logical_not\n",
    "from einops import rearrange, repeat\n",
    "from builderfuncs import restore_model\n",
    "from tabulate import tabulate\n",
    "from ktfuncs import *\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/scaled_U2_data.csv', index_col=0)\n",
    "\n",
    "df.drop(\"UNNAMED: 0\", axis=1, inplace=True)\n",
    "\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA_2_LR_DMP\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns)[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttv_split(ds: tf.data.Dataset, ds_size: int, \n",
    "              train_split: float = 0.8, \n",
    "              val_split: float = 0.1, \n",
    "              test_split: float = 0.1) -> Tuple[tf.data.Dataset, \n",
    "                                                tf.data.Dataset, \n",
    "                                                tf.data.Dataset]:\n",
    "\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "   \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def split_window(features: tf.Tensor) -> Tuple[Dict[tf.Tensor, tf.Tensor],\n",
    "                                               tf.Tensor]:\n",
    "    inputs = features[:12, 1:]\n",
    "    state_labels = features[12, 75:]\n",
    "    targ_labels = tf.expand_dims(features[11, 0], axis=0)\n",
    "    labels = tf.concat([targ_labels, state_labels], axis=0)\n",
    "    inputs.set_shape([12, 247])\n",
    "    labels.set_shape([174])\n",
    "    \n",
    "\n",
    "    return inputs, labels, features\n",
    "\n",
    "                        \n",
    "def make_dataset(data: pd.DataFrame, length: int, \n",
    "                 batch_size: int = 64, multistep: bool = True) -> Tuple[tf.data.Dataset, \n",
    "                                                                        tf.data.Dataset, \n",
    "                                                                        tf.data.Dataset]:\n",
    "    data = np.array(data.iloc[:, :], dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(data=data,\n",
    "                                                        targets=None,\n",
    "                                                        sequence_length=length,\n",
    "                                                        sequence_stride=1,\n",
    "                                                        shuffle=True,\n",
    "                                                        seed=1,\n",
    "                                                        batch_size=None)\n",
    "\n",
    "    ds = ds.filter(lambda x: tf.reduce_all(logical_not(tf.math.is_nan(x))))\n",
    "    ds = ds.map(split_window).batch(batch_size)\n",
    "    # ds = ds.apply(tf.data.experimental.assert_cardinality(170680//batch_size + 1))\n",
    "    train_ds, val_ds, test_ds = ttv_split(ds, 170680//batch_size, train_split=0.8, val_split=0.1, test_split=0.1)\n",
    "    train_ds = train_ds\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_data, val_data, test_data = make_dataset(df, 23, batch_size=bs)\n",
    "test_iter = iter(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = restore_model(\"model_folder/gru_folder\", modeltype=\"gru\")\n",
    "bigru = restore_model(\"model_folder/bigru_folder\", modeltype=\"bigru\")\n",
    "lstm = restore_model(\"model_folder/lstm_folder\", modeltype=\"lstm\")\n",
    "bilstm = restore_model(\"model_folder/bilstm_folder\", modeltype=\"bilstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "class predsandtimes():\n",
    "    def __init__(self, model) -> None:\n",
    "        self.name = model.name\n",
    "        self.model = model\n",
    "        self.preds    = []\n",
    "        self.labels = []\n",
    "        self.times    = []\n",
    "        self.r2s   = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.evs = []\n",
    "\n",
    "    def multistep_pred(self, inpts, ftrs):\n",
    "        preds = []\n",
    "        s1 = time()\n",
    "        for i in range(1, 13):\n",
    "            pred = self.model.predict(inpts, verbose=0)\n",
    "            preds.append(pred)\n",
    "            try:\n",
    "                inpts = inpts[:, 1:, :]\n",
    "                next_step = ftrs[:, 11+i, 1:]\n",
    "                next_step[:,  74:] = pred[:, 1:]\n",
    "                next_step = rearrange(next_step, \"b d -> b 1 d\")\n",
    "                inpts = np.concatenate([inpts, next_step], axis=1)\n",
    "            except IndexError:\n",
    "                break\n",
    "        s2 = time()\n",
    "        self.times.append(s2-s1)\n",
    "        preds = rearrange(np.array(preds), \"t b d -> b t d\")\n",
    "        self.preds.append(preds)\n",
    "        self.labels.append(ftrs[:, 11:, 0])\n",
    "        self.r2s.append(r2_score(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "        self.mses.append(mean_squared_error(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "        self.maes.append(mean_absolute_error(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "        self.evs.append(explained_variance_score(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions from each RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\r"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "metric_list = [predsandtimes(gru), predsandtimes(bigru), predsandtimes(lstm), predsandtimes(bilstm)]\n",
    "\n",
    "for iteration, test1 in enumerate(test_iter):\n",
    "    print(f\"{iteration}\", end='\\r')\n",
    "\n",
    "    test1 = next(test_iter)\n",
    "    inputs = test1[0]\n",
    "    features = test1[2].numpy()\n",
    "\n",
    "    for metric in metric_list:\n",
    "        metric.multistep_pred(inputs, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 MSE        MAE        R2    Exp. Variance\n",
      "------------  ----------  ---------  --------  ---------------\n",
      "gru_model     0.0040916   0.0417484  0.920992         0.9244\n",
      "bigru_model   0.00331878  0.0364155  0.937081         0.938113\n",
      "lstm_model    0.00285724  0.0350658  0.944131         0.946657\n",
      "bilstm_model  0.00276496  0.0340436  0.945564         0.946977\n"
     ]
    }
   ],
   "source": [
    "table = [[metric.name, np.mean(metric.mses), np.mean(metric.maes), np.mean(metric.r2s), np.mean(metric.evs)] for metric in metric_list]\n",
    "headers = [\"name\", \"MSE\", \"MAE\", \"R2\", \"Exp. Variance\"]\n",
    "print(tabulate(table, headers=headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_model 0.011847334761991568\n",
      "bigru_model 0.014533195433253092\n",
      "lstm_model 0.012506076128136182\n",
      "bilstm_model 0.016080541179535238\n"
     ]
    }
   ],
   "source": [
    "for metric in metric_list:\n",
    "    print(metric.name, np.mean(metric.times)/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 26s 11ms/step\n",
      "282/282 [==============================] - 25s 12ms/step\n",
      "282/282 [==============================] - 24s 11ms/step\n",
      "282/282 [==============================] - 27s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.173, 0.367, 0.85, 0.703, 0.627, 0.609, 0.794, 0.778, 0.464, 0.619, 0.615, 0.783, 0.852, 0.261, 0.792, 0.874, 0.111, 0.00403, 0.123, 0.00431, 0.00586, 0.00354, 0.686, 0.735, 0.729, 0.032, 0.78, 0.485, 0.45, 0.266, ..., 0.572, 0.603, 0.718, 0.719, 0.0302, 0.607, 0.614, 0.63, 0.764, 0.747, 0.347, 0.783, 0.538, 0.757, 0.823, 0.704, 0.535, 0.676, 0.833, 0.607, 0.092, 0.0664, 0.116, 0.594, 0.378, 0.417, 0.4, 0.874, 0.646, 0.922],\n",
       "       [0.241, 0.809, 0.259, 0.118, 0.712, 0.626, 0.884, 0.778, 0.507, 0.697, 0.694, 0.41, 0.847, 0.325, 0.792, 0.891, 0.0967, 0.000972, 0.111, 0.00227, 0.00395, 0.00489, 0.519, 0.696, 0.689, 0.701, 0.733, 0.411, 0.438, 0.282, ..., 0.574, 0.565, 0.783, 0.779, 0.0299, 0.594, 0.698, 0.693, 0.794, 0.724, 0.46, 0.589, 0.61, 0.853, 0.867, 0.776, 0.625, 0.671, 0.813, 0.686, 0.193, 0.105, 0.216, 0.603, 0.161, 0.42, 0.349, 0.887, 0.719, 0.935],\n",
       "       [0.502, 0.806, 0.12, 0.562, 0.448, 0.627, 0.743, 0.716, 0.343, 0.456, 0.459, 0.72, 0.883, 0.171, 0.78, 0.773, 0.0992, 0.00479, 0.238, 0.00661, 0.00275, 0.00464, -0.00696, 0.716, 0.712, 0.735, 0.291, 0.00766, 0.653, 0.399, ..., 0.598, 0.635, 0.768, 0.766, 0.0326, 0.723, 0.455, 0.489, 0.735, 0.758, 0.284, 0.531, 0.402, 0.673, 0.699, 0.604, 0.4, 0.794, 0.745, 0.439, 0.079, 0.0834, 0.141, 0.539, 0.00498, 0.419, 0.463, 0.917, 0.498, 0.896],\n",
       "       [0.387, -0.00308, 0.201, 0.259, 0.543, 0.609, 0.869, 0.7, 0.415, 0.54, 0.541, 0.131, 0.901, 0.183, 0.789, 0.814, 0.0921, 0.00243, 0.16, -0.00143, 0.00305, 0.0061, -0.00126, 0.679, 0.67, 0.694, 0.725, -0.00198, 0.662, 0.384, ..., 0.606, 0.617, 0.816, 0.808, 0.0337, 0.826, 0.542, 0.571, 0.732, 0.774, 0.345, 0.547, 0.505, 0.802, 0.757, 0.63, 0.499, 0.722, 0.714, 0.514, 0.26, 0.23, 0.366, 0.555, 0.629, 0.42, 0.423, 0.909, 0.573, 0.892],\n",
       "       [0.215, 1.02, 0.496, 0.91, 0.804, 0.606, 0.885, 0.835, 0.636, 0.772, 0.773, 0.226, 0.847, 0.338, 0.79, 0.912, 0.0875, 0.00351, 0.0652, 0.00347, 0.00249, 0.00599, 0.764, 0.718, 0.717, 0.728, 0.764, 0.545, 0.504, 0.312, ..., 0.549, 0.608, 0.786, 0.789, 0.0352, 0.607, 0.773, 0.777, 0.735, 0.76, 0.586, 0.601, 0.725, 0.88, 0.902, 0.827, 0.722, 0.699, 0.822, 0.757, 0.0999, 0.178, 0.155, 0.617, 0.775, 0.411, 0.376, 0.907, 0.789, 0.955],\n",
       "       [0.197, 0.264, 0.357, 0.74, 0.824, 0.624, 0.868, 0.876, 0.699, 0.82, 0.818, 0.557, 0.82, 0.352, 0.78, 0.887, 0.0979, 0.00533, 0.0916, 0.00185, 0.00255, 0.00566, 0.764, 0.731, 0.728, 0.736, 0.769, 0.533, 0.447, 0.278, ..., 0.556, 0.614, 0.852, 0.849, 0.0303, 0.51, 0.817, 0.792, 0.722, 0.769, 0.579, 0.908, 0.756, 0.883, 0.926, 0.839, 0.756, 0.844, 0.839, 0.793, 0.144, 0.0739, 0.11, 0.632, 0.157, 0.418, 0.389, 0.921, 0.832, 0.964],\n",
       "       [0.185, 0.262, 0.192, 0.0356, 0.827, 0.611, 0.86, 0.878, 0.706, 0.818, 0.818, 0.318, 0.862, 0.349, 0.79, 0.897, 0.104, 0.00048, 0.0869, 0.00205, 0.00499, 0.00294, 0.771, 0.73, 0.732, 0.746, 0.773, 0.545, 0.449, 0.277, ..., 0.545, 0.624, 0.88, 0.878, 0.028, 0.672, 0.816, -0.00768, 0.726, 0.778, 0.615, 0.918, 0.757, 0.875, 0.924, 0.854, 0.758, 0.803, 0.805, 0.795, 0.13, 0.0695, 0.141, 0.628, 0.256, 0.422, 0.422, 0.9, 0.83, 0.964],\n",
       "       [0.192, 0.637, 0.471, 0.0348, 0.859, 0.605, 0.874, 0.903, 0.817, 0.875, 0.876, 0.596, 0.876, 0.419, 0.743, 0.881, 0.106, 0.00474, 0.136, -0.000756, 0.00358, 0.00552, 0.8, 0.758, 0.755, 0.763, 0.803, 0.476, 0.418, 0.265, ..., 0.539, 0.537, 0.881, 0.846, 0.0303, 0.696, 0.875, 0.846, 0.724, 0.706, 0.717, 0.71, 0.83, 0.912, 0.938, 0.883, 0.83, 0.846, 0.86, 0.839, 0.0934, 0.0829, 0.152, 0.632, 0.000584, 0.418, 0.347, 0.919, 0.884, 0.967],\n",
       "       [0.235, 0.637, 0.587, 0.487, 0.807, 0.609, 0.873, 0.83, 0.759, 0.829, 0.829, 0.703, 0.876, 0.356, 0.717, 0.839, 0.108, 0.00335, 0.143, 0.00205, 0.00302, 0.0056, 0.77, 0.731, 0.727, 0.738, 0.771, 0.481, 0.436, 0.269, ..., 0.52, 0.518, 0.876, 0.833, 0.0325, 0.69, 0.829, 0.807, 0.701, 0.678, 0.651, 0.689, 0.791, 0.897, 0.918, 0.838, 0.79, 0.83, 0.812, 0.795, 0.0986, 0.0799, 0.173, 0.623, 0.055, 0.421, 0.336, 0.919, 0.84, 0.95],\n",
       "       [0.193, 0.716, 0.851, 0.442, 0.733, 0.589, 0.848, 0.843, 0.532, 0.728, 0.723, 0.618, 0.841, 0.328, 0.795, 0.898, 0.0837, 0.00371, 0.103, 0.00401, 0.00176, 0.00555, 0.678, 0.667, 0.662, 0.678, 0.702, 0.444, 0.403, 0.269, ..., 0.56, 0.594, 0.798, 0.792, 0.0318, 0.564, 0.727, 0.717, 0.779, 0.743, 0.478, 0.606, 0.66, 0.836, 0.877, 0.798, 0.655, 0.772, 0.849, 0.708, 0.0994, 0.087, 0.172, 0.617, 0.177, 0.414, 0.391, 0.894, 0.748, 0.951],\n",
       "       [0.281, 0.091, 0.621, 0.0681, 0.657, 0.629, 0.859, 0.747, 0.487, 0.63, 0.631, 0.369, 0.785, 0.273, 0.798, 0.899, 0.0821, 0.00206, 0.155, 0.00137, 0.00224, -0.00023, 0.616, 0.622, 0.619, 0.628, 0.656, 0.525, 0.504, 0.308, ..., 0.539, 0.615, 0.854, 0.855, 0.0381, 0.377, 0.631, 0.64, 0.75, 0.762, 0.411, 0.608, 0.581, 0.818, 0.828, 0.756, 0.573, 0.602, 0.779, 0.619, 0.0672, 0.0737, 0.129, 0.584, -0.0155, 0.412, 0.398, 0.931, 0.653, 0.919],\n",
       "       [0.211, 0.278, 0.749, 0.0343, 0.854, 0.599, 0.863, 0.911, 0.683, 0.849, 0.847, 0.356, 0.875, 0.378, 0.778, 0.898, 0.06, 0.00267, 0.0931, 0.00623, 0.00311, 0.00297, 0.799, 0.755, 0.759, 0.768, 0.804, 0.514, 0.463, 0.287, ..., 0.548, 0.649, 0.852, 0.873, 0.0332, 0.741, 0.849, 0.816, 0.748, 0.754, 0.589, 0.647, 0.81, 0.892, 0.932, 0.801, 0.807, 0.692, 0.87, 0.821, 0.193, 0.173, 0.596, 0.628, 0.709, 0.418, 0.423, 0.897, 0.856, 0.975],\n",
       "       [0.194, 0.534, 0.222, 0.268, 0.813, 0.603, 0.864, 0.864, 0.715, 0.816, 0.814, 0.541, 0.888, 0.348, 0.756, 0.876, 0.109, 0.00432, 0.134, 0.00129, 0.00356, 0.00511, 0.76, 0.725, 0.723, 0.732, 0.763, 0.452, 0.414, 0.259, ..., 0.544, 0.563, 0.872, 0.851, 0.031, 0.766, 0.815, -0.00248, 0.734, 0.721, 0.611, 0.683, 0.772, 0.884, 0.916, 0.832, 0.773, 0.82, 0.846, 0.785, 0.116, 0.0838, 0.171, 0.626, 0.0927, 0.419, 0.371, 0.91, 0.828, 0.962],\n",
       "       [0.199, 0.361, 0.602, 0.111, 0.865, 0.607, 0.873, 0.893, 0.73, 0.86, 0.861, 0.451, 0.786, 0.395, 0.782, 0.913, 0.0499, -0.000639, 0.103, -0.000277, 0.000768, 0.000334, 0.791, 0.759, 0.756, 0.774, 0.809, 0.478, 0.426, 0.264, ..., 0.518, 0.615, 0.913, 0.909, 0.0358, 0.4, 0.86, 0.815, 0.719, 0.778, 0.629, 0.691, 0.812, 0.907, 0.939, 0.873, 0.811, 0.694, 0.799, 0.836, 0.0965, 0.0828, 0.186, 0.628, 0.345, 0.416, 0.38, 0.909, 0.87, 0.974],\n",
       "       [0.337, 0.815, 0.714, 0.000932, 0.708, 0.615, 0.867, 0.89, 0.565, 0.705, 0.706, 0.319, 0.847, 0.327, 0.793, 0.926, 0.0817, 0.00237, 0.128, 0.00693, 0.000963, 0.00194, 0.698, 0.673, 0.673, 0.683, 0.706, 0.557, 0.524, 0.315, ..., 0.575, 0.588, 0.832, 0.835, 0.0365, 0.577, 0.709, 0.701, 0.768, 0.75, 0.497, 0.626, 0.652, 0.846, 0.871, 0.767, 0.65, 0.787, 0.866, 0.692, 0.101, 0.11, 0.143, 0.609, 0.662, 0.421, 0.41, 0.936, 0.727, 0.965],\n",
       "       [0.24, 0.711, 0.238, 0.684, 0.786, 0.609, 0.867, 0.879, 0.679, 0.795, 0.796, 0.845, 0.852, 0.342, 0.795, 0.905, 0.0988, -0.000829, 0.118, -0.00135, 0.00256, 0.00682, 0.764, 0.707, 0.711, 0.728, 0.751, 0.46, 0.407, 0.26, ..., 0.568, 0.643, 0.875, 0.866, 0.0322, 0.595, 0.795, 0.773, 0.731, 0.79, 0.582, 0.705, 0.739, 0.879, 0.901, 0.834, 0.739, 0.757, 0.886, 0.768, 0.0704, 0.081, 0.163, 0.624, -0.0147, 0.418, 0.415, 0.921, 0.811, 0.965],\n",
       "       [0.201, 0.633, 0.16, 0.799, 0.782, 0.611, 0.862, 0.868, 0.604, 0.784, 0.784, 0.709, 0.865, 0.343, 0.796, 0.899, 0.0752, 0.00164, 0.0845, -0.000177, -0.0004, 0.00327, 0.747, 0.703, 0.707, 0.721, 0.744, 0.46, 0.403, 0.261, ..., 0.549, 0.674, 0.867, 0.861, 0.0332, 0.658, 0.783, 0.766, 0.718, 0.797, 0.538, 0.652, 0.733, 0.872, 0.902, 0.81, 0.735, 0.743, 0.844, 0.758, 0.0969, 0.085, 0.163, 0.615, 0.368, 0.418, 0.431, 0.884, 0.799, 0.96],\n",
       "       [0.263, 0.736, 0.00596, 0.275, 0.869, 0.607, 0.89, 0.907, 0.734, 0.874, 0.876, 0.537, 0.861, 0.409, 0.776, 0.909, 0.0858, 0.00417, 0.097, 0.00365, 0.00338, 0.00256, 0.832, 0.789, 0.788, 0.8, 0.82, 0.536, 0.442, 0.302, ..., 0.528, 0.645, 0.891, 0.89, 0.0269, 0.655, 0.874, 0.85, 0.72, 0.766, 0.679, 0.649, 0.841, 0.923, 0.942, 0.861, 0.839, 0.76, 0.884, 0.842, 0.107, 0.158, 0.224, 0.632, 0.255, 0.417, 0.403, 0.882, 0.884, 0.972],\n",
       "       [0.82, 0.449, 0.554, 0.391, 0.2, 0.601, 0.763, 0.612, 0.0918, 0.233, 0.232, 0.561, 0.829, 0.123, 0.758, 0.681, 0.196, 0.217, 0.354, 0.00275, 0.0095, 0.0154, -0.000247, 0.686, 0.692, 0.0588, 0.000961, -0.00877, 0.583, 0.332, ..., 0.67, 0.647, 0.827, 0.803, 0.0392, 0.548, 0.231, -0.00433, 0.756, 0.703, 0.125, 0.403, 0.182, 0.647, 0.51, 0.441, 0.192, 0.649, 0.694, 0.226, 0.117, 0.0727, 0.151, 0.472, 0.247, 0.414, 0.514, 0.911, 0.29, 0.856],\n",
       "       [0.536, 0.901, 0.0519, 0.532, 0.395, 0.612, 0.76, 0.709, 0.304, 0.402, 0.404, 0.543, 0.816, 0.167, 0.775, 0.769, 0.112, 0.00672, 0.282, 0.00716, 0.00436, 0.00693, -0.0098, 0.733, 0.736, 0.738, -0.00714, 0.00046, 0.675, 0.39, ..., 0.574, 0.642, 0.745, 0.739, 0.0293, 0.509, 0.408, 0.454, 0.739, 0.742, 0.253, 0.497, 0.351, 0.676, 0.663, 0.561, 0.35, 0.743, 0.742, 0.393, 0.119, 0.0889, 0.144, 0.53, 0.649, 0.423, 0.503, 0.926, 0.448, 0.882],\n",
       "       [0.18, 0.911, 0.27, -0.00394, 0.872, 0.596, 0.881, 0.923, 0.72, 0.864, 0.863, 0.362, 0.872, 0.408, 0.792, 0.895, 0.0811, 0.00496, 0.0913, 1.01, 0.00181, -0.00191, 0.815, 0.771, 0.768, 0.783, 0.779, 0.492, 0.432, 0.272, ..., 0.546, 0.608, 0.863, 0.853, 0.0355, 0.687, 0.864, 0.837, 0.753, 0.76, 0.664, 0.638, 0.819, 0.913, 0.943, 0.874, 0.815, 0.733, 0.818, 0.843, 0.0829, 0.0778, 0.133, 0.63, 0.541, 0.418, 0.405, 0.901, 0.873, 0.978],\n",
       "       [0.234, 1.01, 0.569, 0.00846, 0.821, 0.611, 0.884, 0.856, 0.674, 0.803, 0.802, 0.196, 0.887, 0.344, 0.791, 0.916, 0.0782, 0.00195, 0.0894, -0.00229, 0.00431, 0.00271, 0.778, 0.74, 0.734, 0.749, 0.78, 0.547, 0.51, 0.314, ..., 0.533, 0.615, 0.84, 0.839, 0.0301, 0.761, 0.804, 0.799, 0.734, 0.772, 0.625, 0.608, 0.763, 0.892, 0.918, 0.863, 0.758, 0.717, 0.802, 0.781, 0.104, 0.0902, 0.142, 0.624, 0.777, 0.413, 0.388, 0.906, 0.815, 0.963],\n",
       "       [0.227, 0.365, 0.00929, 0.843, 0.803, 0.618, 0.836, 0.883, 0.706, 0.802, 0.804, 0.492, 0.813, 0.344, 0.789, 0.893, 0.0801, 0.00149, 0.116, 0.00462, 0.00302, 0.00615, 0.768, 0.719, 0.715, 0.731, 0.764, 0.554, 0.46, 0.285, ..., 0.542, 0.624, 0.844, 0.843, 0.0295, 0.48, 0.803, 0.78, 0.743, 0.759, 0.573, 0.882, 0.745, 0.854, 0.914, 0.826, 0.745, 0.871, 0.871, 0.774, 0.305, 0.0792, 0.157, 0.627, 0.241, 0.421, 0.417, 0.898, 0.819, 0.966],\n",
       "       [0.175, 0.28, 0.392, 0.795, 0.833, 0.606, 0.864, 0.902, 0.668, 0.822, 0.822, 0.354, 0.837, 0.35, 0.79, 0.908, 0.0676, 0.00176, 0.1, 0.000519, 0.00373, 0.00405, 0.771, 0.736, 0.736, 0.751, 0.775, 0.508, 0.485, 0.293, ..., 0.553, 0.617, 0.831, 0.835, 0.0319, 0.593, 0.82, 0.794, 0.786, 0.727, 0.559, 0.639, 0.772, 0.884, 0.927, 0.793, 0.767, 0.686, 0.895, 0.797, 0.114, 0.0854, 0.136, 0.625, 0.835, 0.416, 0.412, 0.906, 0.833, 0.97],\n",
       "       [0.0102, 0.126, 0.134, 0.634, 0.462, 0.416, 0.839, 0.691, 0.305, 0.475, 0.461, 0.407, 0.819, 0.187, 0.643, 0.66, 0.147, 0.00623, 0.276, 0.0188, 0.0163, 0.324, 0.0147, 0.665, 0.707, 0.605, 0.322, 0.00661, 0.548, 0.352, ..., 0.458, 0.541, 0.839, 0.851, 0.0509, 0.48, 0.459, 0.523, 0.582, 0.609, 0.29, 0.576, 0.461, 0.762, 0.724, 0.636, 0.457, 0.477, 0.603, 0.452, 0.213, 0.15, 0.242, 0.595, 0.77, 0.384, 0.408, 0.907, 0.509, 0.867],\n",
       "       [0.22, 0.645, 0.678, 0.781, 0.781, 0.598, 0.872, 0.851, 0.676, 0.789, 0.789, 0.774, 0.857, 0.339, 0.77, 0.878, 0.097, 0.00202, 0.134, 0.00404, 0.00286, 0.00531, 0.745, 0.703, 0.704, 0.714, 0.742, 0.457, 0.425, 0.264, ..., 0.559, 0.566, 0.852, 0.841, 0.0296, 0.613, 0.788, 0.777, 0.752, 0.724, 0.572, 0.684, 0.744, 0.883, 0.901, 0.817, 0.74, 0.84, 0.835, 0.763, 0.0623, 0.079, 0.169, 0.621, -0.00267, 0.416, 0.357, 0.919, 0.804, 0.957],\n",
       "       [0.639, 0.93, 0.6, 0.882, 0.286, 0.608, 0.784, 0.66, 0.145, 0.298, 0.3, 0.226, 0.899, 0.102, 0.798, 0.787, 0.164, 0.0171, 0.255, 0.00283, 0.00244, 0.00222, 0.728, 0.689, 0.345, 0.0382, -0.0031, 0.728, 0.73, 0.295, ..., 0.657, 0.626, 0.762, 0.755, 0.0332, 0.788, 0.297, 0.368, 0.787, 0.735, 0.182, 0.425, 0.259, 0.681, 0.567, 0.442, 0.259, 0.658, 0.75, 0.287, 0.135, 0.195, 0.298, 0.499, 0.638, 0.418, 0.509, 0.925, 0.349, 0.868],\n",
       "       [0.323, 0.826, 0.00421, 0.68, 0.877, 0.63, 0.884, 0.873, 0.814, 0.881, 0.881, 0.635, 0.861, 0.443, 0.763, 0.908, 0.0739, 0.00137, 0.105, 0.00572, 0.00228, 0.00506, 0.848, 0.808, 0.814, 0.814, 0.858, 0.565, 0.519, 0.316, ..., 0.536, 0.567, 0.858, 0.844, 0.0292, 0.618, 0.881, 0.843, 0.736, 0.728, 0.711, 0.711, 0.842, 0.923, 0.941, 0.874, 0.833, 0.873, 0.863, 0.847, 0.107, 0.0746, 0.128, 0.634, -0.0156, 0.423, 0.344, 0.933, 0.888, 0.966],\n",
       "       [0.21, 0.273, 0.567, 0.0196, 0.809, 0.613, 0.87, 0.869, 0.65, 0.805, 0.805, 0.514, 0.821, 0.343, 0.788, 0.908, 0.0518, 0.00261, 0.092, -0.000227, 0.00264, 0.00117, 0.772, 0.721, 0.726, 0.736, 0.768, 0.505, 0.459, 0.282, ..., 0.536, 0.664, 0.86, 0.863, 0.0348, 0.529, 0.807, 0.788, 0.735, 0.766, 0.537, 0.667, 0.763, 0.882, 0.916, 0.803, 0.759, 0.684, 0.83, 0.783, 0.489, 0.0836, 0.257, 0.617, 0.83, 0.422, 0.437, 0.894, 0.82, 0.966],\n",
       "       [0.594, 0.0815, 0.821, 0.511, 0.387, 0.63, 0.878, 0.822, 0.247, 0.423, 0.43, 0.343, 0.904, 0.17, 0.781, 0.898, 0.106, 0.00411, 0.209, 0.0154, 0.00334, 0.00431, -0.00612, 0.721, 0.717, 0.739, 0.00104, 1.76e-05, 0.717, 0.404, ..., 0.504, 0.618, 0.761, 0.756, 0.0358, 0.874, 0.428, 0.463, 0.751, 0.734, 0.238, 0.48, 0.361, 0.774, 0.691, 0.635, 0.359, 0.563, 0.783, 0.417, 0.0867, 0.0769, 0.161, 0.532, 0.838, 0.418, 0.387, 0.908, 0.466, 0.929],\n",
       "       ...,\n",
       "       [0.2, 0.0431, 0.369, 0.0172, 0.812, 0.598, 0.844, 0.884, 0.639, 0.794, 0.791, 0.241, 0.842, 0.335, 0.792, 0.902, 0.11, 0.00109, 0.104, -0.00184, 0.00417, 0.00267, 0.762, 0.718, 0.729, 0.735, 0.772, 0.546, 0.516, 0.313, ..., 0.601, 0.574, 0.797, 0.793, 0.0274, 0.602, 0.79, 0.766, 0.779, 0.737, 0.555, 0.624, 0.716, 0.855, 0.912, 0.813, 0.722, 0.725, 0.891, 0.771, 0.111, 0.0888, 0.176, 0.622, 0.164, 0.408, 0.368, 0.907, 0.808, 0.966],\n",
       "       [0.197, 0.449, 0.267, 0.442, 0.851, 0.621, 0.863, 0.902, 0.745, 0.858, 0.859, 0.724, 0.844, 0.388, 0.791, 0.888, 0.0726, 0.00484, 0.0929, 0.00524, 0.00427, 0.00673, 0.741, 0.749, 0.75, 0.766, 0.786, 0.474, 0.391, 0.245, ..., 0.534, 0.666, 0.859, 0.856, 0.028, 0.612, 0.858, 0.822, 0.721, 0.788, 0.592, 0.868, 0.807, 0.896, 0.935, 0.842, 0.807, 0.812, 0.883, 0.823, 0.101, 0.0739, 0.117, 0.633, 0.414, 0.424, 0.419, 0.89, 0.868, 0.974],\n",
       "       [0.22, 0.555, 0.185, 0.511, 0.814, 0.61, 0.868, 0.871, 0.74, 0.836, 0.837, 0.749, 0.88, 0.361, 0.751, 0.869, 0.106, 0.0025, 0.132, 0.000945, 0.00499, 0.00496, 0.775, 0.728, 0.729, 0.739, 0.773, 0.438, 0.396, 0.246, ..., 0.548, 0.568, 0.868, 0.843, 0.032, 0.73, 0.834, -0.00872, 0.722, 0.723, 0.629, 0.7, 0.795, 0.894, 0.923, 0.84, 0.791, 0.827, 0.859, 0.803, 0.113, 0.0833, 0.154, 0.624, -0.00399, 0.419, 0.363, 0.91, 0.847, 0.962],\n",
       "       [0.134, 0.459, 0.625, 0.854, 0.886, 0.593, 0.866, 0.971, 0.8, 0.895, 0.898, 0.725, 0.847, 0.454, 0.791, 0.901, 0.0808, 0.00227, 0.107, 1, -0.000894, 0.00321, 0.811, 0.76, 0.762, 0.769, 0.807, 0.446, 0.359, 0.237, ..., 0.525, 0.665, 0.87, 0.86, 0.0319, 0.627, 0.896, 0.864, 0.719, 0.791, 0.633, 0.811, 0.847, 0.912, 0.954, 0.883, 0.845, 0.812, 0.896, 0.862, 0.131, 0.0729, 0.125, 0.647, 0.368, 0.417, 0.429, 0.889, 0.904, 0.982],\n",
       "       [0.22, 0.819, 0.00894, 0.47, 0.81, 0.612, 0.885, 0.859, 0.628, 0.807, 0.806, 0.592, 0.88, 0.344, 0.792, 0.893, 0.0753, 0.00371, 0.0901, 0.00233, 0.00232, 0.00217, 0.76, 0.728, 0.716, 0.737, 0.761, 0.482, 0.424, 0.281, ..., 0.559, 0.634, 0.849, 0.843, 0.0311, 0.713, 0.808, 0.782, 0.748, 0.763, 0.563, 0.616, 0.757, 0.899, 0.914, 0.822, 0.756, 0.818, 0.865, 0.782, 0.281, 0.135, 0.32, 0.629, 0.157, 0.419, 0.402, 0.876, 0.821, 0.963],\n",
       "       [0.165, 0.844, 0.356, 0.767, 0.849, 0.611, 0.889, 0.888, 0.68, 0.837, 0.837, 0.388, 0.815, 0.369, 0.782, 0.897, 0.0799, 0.00336, 0.0704, 0.00365, 0.00274, 0.00556, 0.787, 0.742, 0.741, 0.75, 0.783, 0.522, 0.449, 0.294, ..., 0.549, 0.633, 0.863, 0.86, 0.0294, 0.459, 0.838, 0.812, 0.729, 0.763, 0.625, 0.618, 0.791, 0.91, 0.929, 0.832, 0.788, 0.825, 0.874, 0.809, 0.118, 0.0824, 0.216, 0.632, 0.119, 0.417, 0.406, 0.893, 0.848, 0.967],\n",
       "       [0.658, 0.000722, 0.125, 0.352, 0.339, 0.607, 0.804, 0.617, 0.314, 0.371, 0.372, 0.294, 0.876, 0.168, 0.704, 0.612, 0.221, 0.0056, 0.323, 0.00519, 0.00696, 0.00612, -0.00249, 0.676, 0.673, 0.684, -0.00205, -0.00951, 0.668, 0.386, ..., 0.593, 0.52, 0.832, 0.811, 0.0356, 0.727, 0.37, 0.426, 0.694, 0.655, 0.27, 0.504, 0.343, 0.713, 0.627, 0.471, 0.339, 0.575, 0.548, 0.352, 0.122, 0.232, 0.327, 0.517, 0.621, 0.416, 0.449, 0.914, 0.414, 0.848],\n",
       "       [0.223, 0.356, 0.442, 0.631, 0.805, 0.617, 0.839, 0.897, 0.69, 0.81, 0.812, 0.813, 0.859, 0.344, 0.778, 0.891, 0.0916, 0.00175, 0.126, 0.00172, 0.00163, 0.00211, 0.765, 0.726, 0.728, 0.736, 0.768, 0.467, 0.437, 0.26, ..., 0.533, 0.617, 0.879, 0.875, 0.0317, 0.668, 0.811, 0.79, 0.729, 0.763, 0.571, 0.695, 0.764, 0.861, 0.918, 0.835, 0.76, 0.67, 0.862, 0.787, 0.105, 0.0739, 0.174, 0.619, 0.281, 0.419, 0.413, 0.908, 0.825, 0.971],\n",
       "       [0.186, 0.823, 0.523, 0.734, 0.891, 0.577, 0.888, 0.953, 0.715, 0.881, 0.882, 0.482, 0.845, 0.453, 0.798, 0.89, 0.0739, 0.000809, 0.056, 1, 0.00377, 0.00248, 0.83, 0.777, 0.781, 0.782, 0.825, 0.496, 0.423, 0.283, ..., 0.57, 0.635, 0.843, 0.832, 0.0243, 0.585, 0.88, 0.844, 0.749, 0.775, 0.641, 0.655, 0.82, 0.921, 0.953, 0.879, 0.817, 0.801, 0.841, 0.858, 0.0805, 0.081, 0.251, 0.632, 0.131, 0.417, 0.391, 0.894, 0.89, 0.98],\n",
       "       [0.192, -0.00376, 0.407, 0.798, 0.878, 0.621, 0.876, 0.896, 0.711, 0.86, 0.859, 0.311, 0.897, 0.393, 0.789, 0.915, 0.0777, 0.00322, 0.0955, 0.00395, 0.00287, 0.00438, 0.806, 0.769, 0.764, 0.777, 0.81, 0.532, 0.482, 0.296, ..., 0.54, 0.639, 0.843, 0.838, 0.0293, 0.807, 0.859, 0.822, 0.732, 0.776, 0.644, 0.644, 0.796, 0.903, 0.942, 0.877, 0.794, 0.723, 0.846, 0.832, 0.387, 0.0856, 0.243, 0.633, 0.0519, 0.413, 0.376, 0.893, 0.869, 0.975],\n",
       "       [0.217, 0.564, 0.181, 0.88, 0.82, 0.618, 0.857, 0.896, 0.703, 0.824, 0.822, 0.745, 0.857, 0.353, 0.795, 0.9, 0.0809, 0.00364, 0.105, 0.00394, 0.000662, 0.00373, 0.777, 0.73, 0.732, 0.745, 0.774, 0.472, 0.409, 0.261, ..., 0.54, 0.642, 0.865, 0.858, 0.0312, 0.652, 0.824, 0.797, 0.737, 0.777, 0.558, 0.716, 0.767, 0.878, 0.923, 0.837, 0.766, 0.774, 0.868, 0.795, 0.22, 0.105, 0.132, 0.629, 0.272, 0.421, 0.423, 0.887, 0.836, 0.972],\n",
       "       [0.2, 0.909, 0.0596, 0.62, 0.787, 0.614, 0.88, 0.824, 0.591, 0.774, 0.774, 0.553, 0.884, 0.34, 0.794, 0.897, 0.092, 0.00465, 0.0931, 1, 0.00338, 0.00512, 0.731, 0.697, 0.695, 0.715, 0.744, 0.475, 0.43, 0.266, ..., 0.559, 0.631, 0.862, 0.86, 0.0306, 0.734, 0.773, 0.758, 0.753, 0.762, 0.535, 0.619, 0.721, 0.88, 0.898, 0.804, 0.716, 0.729, 0.86, 0.754, 0.0775, 0.0707, 0.133, 0.626, 0.0284, 0.417, 0.407, 0.905, 0.789, 0.954],\n",
       "       [0.408, 0.805, 0.514, 0.504, 0.571, 0.617, 0.869, 0.871, 0.385, 0.592, 0.592, 0.543, 0.877, 0.225, 0.781, 0.877, 0.109, 0.00742, 0.147, 1.01, 0.0051, -0.00358, 0.31, 0.764, 0.771, 0.779, 0.276, 0.355, 0.544, 0.339, ..., 0.565, 0.605, 0.809, 0.806, 0.0301, 0.706, 0.595, 0.594, 0.744, 0.744, 0.369, 0.567, 0.517, 0.813, 0.801, 0.705, 0.516, 0.755, 0.843, 0.581, 0.122, 0.0754, 0.309, 0.575, 0.117, 0.418, 0.384, 0.896, 0.622, 0.941],\n",
       "       [0.221, 0.634, 0.231, 0.599, 0.805, 0.621, 0.871, 0.883, 0.626, 0.806, 0.806, 0.843, 0.861, 0.349, 0.796, 0.908, 0.0779, 0.00206, 0.0896, 0.0057, 0.00332, 0.00237, 0.77, 0.729, 0.729, 0.738, 0.766, 0.474, 0.415, 0.271, ..., 0.551, 0.632, 0.873, 0.865, 0.0275, 0.636, 0.806, 0.784, 0.749, 0.769, 0.557, 0.663, 0.76, 0.886, 0.914, 0.819, 0.757, 0.775, 0.868, 0.779, 0.177, 0.0847, 0.142, 0.626, 0.298, 0.422, 0.416, 0.892, 0.82, 0.967],\n",
       "       [0.247, 0.923, 0.542, 0.6, 0.812, 0.622, 0.838, 0.864, 0.632, 0.811, 0.812, 0.445, 0.889, 0.346, 0.774, 0.903, 0.0737, 0.00277, 0.0859, 0.00226, 0.00134, 0.00299, 0.768, 0.734, 0.728, 0.742, 0.779, 0.488, 0.432, 0.274, ..., 0.541, 0.586, 0.806, 0.803, 0.0311, 0.757, 0.811, 0.793, 0.745, 0.733, 0.579, 0.612, 0.751, 0.855, 0.919, 0.838, 0.75, 0.749, 0.85, 0.789, 0.0726, 0.0887, 0.134, 0.612, -0.0468, 0.416, 0.356, 0.906, 0.825, 0.965],\n",
       "       [0.199, 0.933, 0.72, 0.0102, 0.806, 0.609, 0.844, 0.889, 0.651, 0.809, 0.808, 0.276, 0.839, 0.35, 0.789, 0.899, 0.0983, 0.00256, 0.0927, 0.00211, 0.00468, 0.0049, 0.762, 0.714, 0.716, 0.723, 0.753, 0.494, 0.436, 0.279, ..., 0.569, 0.632, 0.856, 0.852, 0.0299, 0.566, 0.809, 0.792, 0.736, 0.769, 0.597, 0.601, 0.76, 0.864, 0.915, 0.81, 0.763, 0.779, 0.887, 0.781, 0.0893, 0.0737, 0.202, 0.619, 0.135, 0.42, 0.424, 0.902, 0.823, 0.969],\n",
       "       [1.07, 0.0752, 0.611, 0.517, 0.149, 0.61, 0.752, 0.779, 0.051, 0.2, 0.206, 0.507, 0.828, 0.118, 0.755, 0.758, 0.225, 0.0119, 0.374, 0.00967, 0.0108, 0.0108, 0.000503, 0.637, 0.638, 0.0402, 0.000648, -0.00981, 0.701, 0.383, ..., 0.644, 0.638, 0.858, 0.886, 0.0306, 0.539, 0.201, 0.278, 0.726, 0.703, 0.126, 0.379, 0.17, 0.641, 0.474, 0.388, 0.161, 0.58, 0.798, 0.195, 0.0927, 0.0799, 0.129, 0.457, 0.117, 0.407, 0.538, 0.912, 0.263, 0.89],\n",
       "       [0.267, 0.824, 0.524, 0.64, 0.711, 0.633, 0.905, 0.774, 0.497, 0.693, 0.689, 0.577, 0.862, 0.325, 0.787, 0.878, 0.0863, 0.00301, 0.109, 1, -0.000634, 0.000585, 0.68, 0.67, 0.676, 0.691, 0.665, 0.498, 0.449, 0.295, ..., 0.558, 0.558, 0.795, 0.783, 0.033, 0.635, 0.693, 0.685, 0.785, 0.73, 0.446, 0.612, 0.622, 0.87, 0.861, 0.767, 0.614, 0.676, 0.798, 0.685, 0.179, 0.0894, 0.196, 0.602, 0.133, 0.421, 0.354, 0.904, 0.719, 0.927],\n",
       "       [0.268, 0.916, 0.729, 0.763, 0.804, 0.614, 0.855, 0.877, 0.618, 0.806, 0.809, 0.293, 0.922, 0.339, 0.79, 0.909, 0.0736, -0.00105, 0.0619, 0.00241, 0.00203, 0.00253, 0.775, 0.728, 0.731, 0.74, 0.779, 0.52, 0.45, 0.287, ..., 0.572, 0.608, 0.786, 0.779, 0.0329, 0.884, 0.809, 0.801, 0.758, 0.75, 0.569, 0.593, 0.761, 0.871, 0.911, 0.801, 0.757, 0.828, 0.888, 0.78, 0.277, 0.172, 0.365, 0.614, 0.0928, 0.421, 0.376, 0.887, 0.82, 0.969],\n",
       "       [0.189, -0.00273, 0.408, 0.334, 0.791, 0.619, 0.875, 0.833, 0.605, 0.771, 0.771, 0.263, 0.887, 0.338, 0.79, 0.901, 0.087, 0.00395, 0.101, 0.00268, 0.000887, 0.00556, 0.741, 0.703, 0.697, 0.708, 0.74, 0.534, 0.48, 0.298, ..., 0.542, 0.637, 0.86, 0.858, 0.03, 0.768, 0.77, 0.746, 0.731, 0.774, 0.542, 0.604, 0.714, 0.874, 0.899, 0.808, 0.711, 0.714, 0.848, 0.747, 0.11, 0.0847, 0.17, 0.616, 0.127, 0.412, 0.399, 0.907, 0.786, 0.956],\n",
       "       [0.188, 0.647, 0.0242, 0.564, 0.809, 0.623, 0.875, 0.88, 0.695, 0.816, 0.814, 0.787, 0.869, 0.349, 0.786, 0.904, 0.076, 0.0017, 0.143, 0.00204, 0.00133, 0.00312, 0.76, 0.713, 0.713, 0.728, 0.76, 0.437, 0.398, 0.248, ..., 0.533, 0.61, 0.872, 0.867, 0.0308, 0.68, 0.816, -0.00888, 0.747, 0.756, 0.589, 0.7, 0.762, 0.891, 0.918, 0.854, 0.76, 0.751, 0.876, 0.791, 0.143, 0.088, 0.166, 0.627, -0.0203, 0.422, 0.387, 0.913, 0.829, 0.965],\n",
       "       [0.228, 0.363, 0.377, 0.883, 0.826, 0.623, 0.845, 0.898, 0.66, 0.829, 0.829, 0.495, 0.864, 0.36, 0.789, 0.908, 0.0561, 0.00148, 0.0951, 0.00215, 0.00159, 0.00596, 0.78, 0.733, 0.738, 0.752, 0.788, 0.508, 0.464, 0.279, ..., 0.541, 0.65, 0.834, 0.842, 0.0351, 0.695, 0.83, 0.789, 0.723, 0.783, 0.559, 0.657, 0.766, 0.869, 0.924, 0.816, 0.766, 0.724, 0.859, 0.805, 0.149, 0.108, 0.55, 0.621, 0.356, 0.419, 0.413, 0.899, 0.838, 0.974],\n",
       "       [0.297, 0.368, 0.475, 0.755, 0.808, 0.606, 0.868, 0.894, 0.689, 0.813, 0.814, 0.618, 0.866, 0.344, 0.79, 0.85, 0.0678, 0.000634, 0.112, 0.00508, 0.00664, 0.00635, 0.796, 0.756, 0.754, 0.771, 0.796, 0.517, 0.497, 0.314, ..., 0.533, 0.641, 0.79, 0.793, 1.01, 0.7, 0.816, 0.791, 0.749, 0.761, 0.615, 0.641, 0.757, 0.883, 0.899, 0.804, 0.751, 0.936, 0.857, 0.763, 0.123, 0.247, 0.296, 0.503, 0.628, 0.417, 0.426, 0.946, 0.825, 0.969],\n",
       "       [0.214, 0.745, 0.61, 0.916, 0.799, 0.61, 0.891, 0.839, 0.612, 0.792, 0.792, 0.471, 0.904, 0.342, 0.791, 0.899, 0.081, 0.00196, 0.0854, 0.00186, 0.00477, -1.49e-05, 0.759, 0.715, 0.712, 0.72, 0.758, 0.471, 0.409, 0.269, ..., 0.553, 0.633, 0.868, 0.86, 0.0337, 0.811, 0.792, 0.777, 0.745, 0.77, 0.559, 0.618, 0.742, 0.899, 0.909, 0.824, 0.743, 0.744, 0.835, 0.772, 0.0977, 0.09, 0.336, 0.625, 0.209, 0.42, 0.41, 0.884, 0.806, 0.959],\n",
       "       [0.413, 0.566, 0.838, 0.434, 0.653, 0.646, 0.776, 0.797, 0.561, 0.657, 0.655, 0.696, 0.897, 0.306, 0.789, 0.878, 0.0961, -0.00974, 0.12, -0.00368, 0.000945, -0.0109, 0.874, 0.799, -0.0441, 0.833, 0.861, 0.577, 0.538, -0.0282, ..., 0.569, 0.548, 0.687, 0.681, 0.0212, 0.8, 0.652, 0.66, 0.783, 0.715, 0.429, 0.609, 0.564, 0.748, 0.838, 0.759, 0.556, 0.799, 0.86, 0.641, 0.19, 0.0801, 0.157, 0.541, 0.322, 0.428, 0.357, 0.871, 0.678, 0.932],\n",
       "       [0.84, 0.371, 0.146, 0.318, 0.274, 0.597, 0.775, 0.642, 0.151, 0.32, 0.327, 0.419, 0.841, 0.114, 0.769, 0.676, 0.124, 0.00417, 0.268, 0.00893, 0.00511, 0.00268, -0.0102, 0.676, 0.677, 0.515, -0.000116, -0.00662, 0.675, 0.396, ..., 0.631, 0.613, 0.766, 0.789, 0.997, 0.607, 0.32, 0.374, 0.781, 0.695, 0.183, 0.441, 0.278, 0.669, 0.585, 0.415, 0.271, 0.758, 0.652, 0.307, 0.107, 0.178, 0.314, 0.393, 0.566, 0.41, 0.491, 0.959, 0.372, 0.86],\n",
       "       [0.265, 0.909, 0.726, 0.908, 0.797, 0.607, 0.857, 0.877, 0.596, 0.792, 0.797, 0.236, 0.926, 0.342, 0.799, 0.916, 0.0758, 0.00225, 0.0596, 0.00199, 0.00225, 0.00394, 0.767, 0.726, 0.73, 0.733, 0.77, 0.519, 0.464, 0.298, ..., 0.569, 0.61, 0.796, 0.795, 0.035, 0.89, 0.796, 0.788, 0.773, 0.756, 0.558, 0.591, 0.74, 0.867, 0.911, 0.806, 0.738, 0.767, 0.877, 0.775, 0.101, 0.102, 0.301, 0.613, 0.146, 0.422, 0.385, 0.899, 0.808, 0.97],\n",
       "       [0.209, 0.828, 0.561, 0.114, 0.811, 0.602, 0.894, 0.845, 0.595, 0.788, 0.789, 0.352, 0.836, 0.346, 0.805, 0.903, 0.0753, 0.0037, 0.0678, 1, -0.000219, 0.00368, 0.759, 0.721, 0.72, 0.729, 0.769, 0.511, 0.45, 0.29, ..., 0.576, 0.635, 0.814, 0.811, 0.0312, 0.536, 0.79, 0.766, 0.752, 0.779, 0.54, 0.593, 0.724, 0.891, 0.909, 0.815, 0.719, 0.782, 0.835, 0.772, 0.107, 0.119, 0.204, 0.623, 0.127, 0.42, 0.398, 0.894, 0.803, 0.96],\n",
       "       [0.363, 0.923, 0.0802, 0.788, 0.585, 0.559, 0.833, 0.906, 0.458, 0.597, 0.597, 0.327, 0.878, 0.242, 0.781, 0.876, 0.0788, 0.00272, 0.145, 0.00303, 0.0061, 0.00563, 0.0287, 0.71, 0.71, 0.722, 0.745, 0.036, 0.567, 0.345, ..., 0.596, 0.623, 0.828, 0.817, 0.0344, 0.644, 0.601, 0.621, 0.715, 0.778, 0.41, 0.584, 0.566, 0.788, 0.805, 0.713, 0.562, 0.817, 0.799, 0.575, 0.233, 0.192, 0.305, 0.583, 0.748, 0.411, 0.438, 0.922, 0.628, 0.952],\n",
       "       [0.19, 0.274, 0.341, 0.35, 0.832, 0.595, 0.871, 0.892, 0.731, 0.83, 0.829, 0.388, 0.84, 0.358, 0.78, 0.878, 0.102, 0.00496, 0.111, 0.00307, 0.00538, 0.00595, 0.778, 0.736, 0.733, 0.743, 0.781, 0.536, 0.443, 0.28, ..., 0.542, 0.624, 0.903, 0.901, 0.0329, 0.59, 0.83, 0.805, 0.718, 0.77, 0.629, 0.915, 0.783, 0.89, 0.93, 0.861, 0.78, 0.825, 0.812, 0.804, 0.208, 0.0696, 0.13, 0.633, 0.254, 0.416, 0.421, 0.906, 0.842, 0.967]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.predict(test_data)\n",
    "bigru.predict(test_data)\n",
    "lstm.predict(test_data)\n",
    "bilstm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_proj_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
