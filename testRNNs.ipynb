{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import logical_not\n",
    "from einops import rearrange, repeat\n",
    "from builderfuncs import restore_model\n",
    "from tabulate import tabulate\n",
    "from ktfuncs import *\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/scaled_U2_data.csv', index_col=0)\n",
    "\n",
    "df.drop(\"UNNAMED: 0\", axis=1, inplace=True)\n",
    "\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(devices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttv_split(ds: tf.data.Dataset, ds_size: int, \n",
    "              train_split: float = 0.8, \n",
    "              val_split: float = 0.1, \n",
    "              test_split: float = 0.1) -> Tuple[tf.data.Dataset, \n",
    "                                                tf.data.Dataset, \n",
    "                                                tf.data.Dataset]:\n",
    "\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "   \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def split_window(features: tf.Tensor) -> Tuple[Dict[tf.Tensor, tf.Tensor],\n",
    "                                               tf.Tensor]:\n",
    "    inputs = features[:12, 1:]\n",
    "    state_labels = features[12, 75:]\n",
    "    targ_labels = tf.expand_dims(features[11, 0], axis=0)\n",
    "    labels = tf.concat([targ_labels, state_labels], axis=0)\n",
    "    inputs.set_shape([12, 247])\n",
    "    labels.set_shape([174])\n",
    "    \n",
    "\n",
    "    return inputs, labels, features\n",
    "\n",
    "                        \n",
    "def make_dataset(data: pd.DataFrame, length: int, \n",
    "                 batch_size: int = 64, multistep: bool = True) -> Tuple[tf.data.Dataset, \n",
    "                                                                        tf.data.Dataset, \n",
    "                                                                        tf.data.Dataset]:\n",
    "    data = np.array(data.iloc[:, :], dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(data=data,\n",
    "                                                        targets=None,\n",
    "                                                        sequence_length=length,\n",
    "                                                        sequence_stride=1,\n",
    "                                                        shuffle=True,\n",
    "                                                        seed=1,\n",
    "                                                        batch_size=None)\n",
    "\n",
    "    ds = ds.filter(lambda x: tf.reduce_all(logical_not(tf.math.is_nan(x))))\n",
    "    ds = ds.map(split_window).batch(batch_size)\n",
    "    # ds = ds.apply(tf.data.experimental.assert_cardinality(170680//batch_size + 1))\n",
    "    train_ds, val_ds, test_ds = ttv_split(ds, 170680//batch_size, train_split=0.8, val_split=0.1, test_split=0.1)\n",
    "    train_ds = train_ds\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_data, val_data, test_data = make_dataset(df, 23, batch_size=bs)\n",
    "test_iter = iter(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = restore_model(\"model_folder/gru_folder\", modeltype=\"gru\")\n",
    "bigru = restore_model(\"model_folder/bigru_folder\", modeltype=\"bigru\")\n",
    "lstm = restore_model(\"model_folder/lstm_folder\", modeltype=\"lstm\")\n",
    "bilstm = restore_model(\"model_folder/bilstm_folder\", modeltype=\"bilstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "class predsandtimes():\n",
    "    def __init__(self, model) -> None:\n",
    "        self.name = model.name\n",
    "        self.model = model\n",
    "        self.preds    = []\n",
    "        self.labels = []\n",
    "        self.times    = []\n",
    "        self.r2s   = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.evs = []\n",
    "\n",
    "    def multistep_pred(self, inpts, ftrs):\n",
    "        preds = []\n",
    "        s1 = time()\n",
    "        for i in range(1, 13):\n",
    "            pred = self.model.predict(inpts, verbose=0)\n",
    "            preds.append(pred)\n",
    "            try:\n",
    "                inpts = inpts[:, 1:, :]\n",
    "                next_step = ftrs[:, 11+i, 1:]\n",
    "                next_step[:,  74:] = pred[:, 1:]\n",
    "                next_step = rearrange(next_step, \"b d -> b 1 d\")\n",
    "                inpts = np.concatenate([inpts, next_step], axis=1)\n",
    "            except IndexError:\n",
    "                break\n",
    "        s2 = time()\n",
    "        self.times.append(s2-s1)\n",
    "        preds = rearrange(np.array(preds), \"t b d -> b t d\")\n",
    "        self.preds.append(preds)\n",
    "        self.labels.append(ftrs[:, 11:, 0])\n",
    "        self.r2s.append(r2_score(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "        self.mses.append(mean_squared_error(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "        self.maes.append(mean_absolute_error(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "        self.evs.append(explained_variance_score(ftrs[:, 11:, 0], preds[:, :, 0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions from each RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\r"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "metric_list = [predsandtimes(gru), predsandtimes(bigru), predsandtimes(lstm), predsandtimes(bilstm)]\n",
    "\n",
    "for iteration, test1 in enumerate(test_iter):\n",
    "    print(f\"{iteration}\", end='\\r')\n",
    "\n",
    "    test1 = next(test_iter)\n",
    "    inputs = test1[0]\n",
    "    features = test1[2].numpy()\n",
    "\n",
    "    for metric in metric_list:\n",
    "        metric.multistep_pred(inputs, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 MSE        MAE        R2    Exp. Variance\n",
      "------------  ----------  ---------  --------  ---------------\n",
      "gru_model     0.00349377  0.0415791  0.929307         0.931322\n",
      "bigru_model   0.00276085  0.0362202  0.94416          0.944263\n",
      "lstm_model    0.0023954   0.034826   0.951492         0.953017\n",
      "bilstm_model  0.00235463  0.0339577  0.952249         0.952866\n"
     ]
    }
   ],
   "source": [
    "table = [[metric.name, np.mean(metric.mses), np.mean(metric.maes), np.mean(metric.r2s), np.mean(metric.evs)] for metric in metric_list]\n",
    "headers = [\"name\", \"MSE\", \"MAE\", \"R2\", \"Exp. Variance\"]\n",
    "print(tabulate(table, headers=headers))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_proj_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
